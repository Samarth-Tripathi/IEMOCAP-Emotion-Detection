{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import wave\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import LSTM, Input, Flatten, Merge, Embedding, Convolution1D,Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "from features import *\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n",
    "data_path = code_path + \"/../data/sessions/\"\n",
    "sessions = ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']\n",
    "framerate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(data_path + '/../'+'data_collected.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 200, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mocap_head = []\n",
    "\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['mocap_head']\n",
    "    if(x_head.shape != (200,6)):\n",
    "        x_head = np.zeros((200,6))  \n",
    "    x_head[np.isnan(x_head)]=0\n",
    "    mocap_head.append( x_head )\n",
    "    \n",
    "mocap_head = np.array(mocap_head)\n",
    "mocap_head.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = label_binarize(Y,emotions_used)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, return_sequences=False, input_shape=(200, 6)))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 256)               269312    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 302,724\n",
      "Trainable params: 302,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.3925 - acc: 0.3098 - val_loss: 1.3968 - val_acc: 0.3168\n",
      "Epoch 2/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.3154 - acc: 0.3774 - val_loss: 1.3769 - val_acc: 0.3441\n",
      "Epoch 3/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.2857 - acc: 0.4182 - val_loss: 1.3658 - val_acc: 0.3522\n",
      "Epoch 4/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.2641 - acc: 0.4243 - val_loss: 1.3651 - val_acc: 0.3603\n",
      "Epoch 5/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.2483 - acc: 0.4422 - val_loss: 1.3580 - val_acc: 0.3704\n",
      "Epoch 6/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.2370 - acc: 0.4524 - val_loss: 1.3603 - val_acc: 0.3725\n",
      "Epoch 7/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.2292 - acc: 0.4602 - val_loss: 1.3577 - val_acc: 0.3775\n",
      "Epoch 8/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.2180 - acc: 0.4585 - val_loss: 1.3585 - val_acc: 0.3745\n",
      "Epoch 9/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.2069 - acc: 0.4716 - val_loss: 1.3574 - val_acc: 0.3654\n",
      "Epoch 10/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.2004 - acc: 0.4742 - val_loss: 1.3623 - val_acc: 0.3634\n",
      "Epoch 11/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1915 - acc: 0.4858 - val_loss: 1.3666 - val_acc: 0.3573\n",
      "Epoch 12/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1841 - acc: 0.4899 - val_loss: 1.3632 - val_acc: 0.3704\n",
      "Epoch 13/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1771 - acc: 0.4868 - val_loss: 1.3639 - val_acc: 0.3664\n",
      "Epoch 14/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1735 - acc: 0.4911 - val_loss: 1.3548 - val_acc: 0.3725\n",
      "Epoch 15/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1661 - acc: 0.4977 - val_loss: 1.3622 - val_acc: 0.3634\n",
      "Epoch 16/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1645 - acc: 0.4980 - val_loss: 1.3618 - val_acc: 0.3543\n",
      "Epoch 17/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1580 - acc: 0.5071 - val_loss: 1.3656 - val_acc: 0.3593\n",
      "Epoch 18/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1537 - acc: 0.5132 - val_loss: 1.3683 - val_acc: 0.3421\n",
      "Epoch 19/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1454 - acc: 0.5081 - val_loss: 1.3681 - val_acc: 0.3462\n",
      "Epoch 20/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1472 - acc: 0.5046 - val_loss: 1.3612 - val_acc: 0.3684\n",
      "Epoch 21/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1419 - acc: 0.5056 - val_loss: 1.3610 - val_acc: 0.3603\n",
      "Epoch 22/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1345 - acc: 0.5139 - val_loss: 1.3626 - val_acc: 0.3613\n",
      "Epoch 23/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1302 - acc: 0.5205 - val_loss: 1.3549 - val_acc: 0.3755\n",
      "Epoch 24/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1224 - acc: 0.5223 - val_loss: 1.3608 - val_acc: 0.3654\n",
      "Epoch 25/25\n",
      "3948/3948 [==============================] - 12s - loss: 1.1186 - acc: 0.5296 - val_loss: 1.3540 - val_acc: 0.3694\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(mocap_head, Y, \n",
    "                 batch_size=100, nb_epoch=25, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(200, 6)))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               307456    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 308,484\n",
      "Trainable params: 308,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3948/3948 [==============================] - 0s - loss: 10.9097 - acc: 0.3040 - val_loss: 9.9780 - val_acc: 0.3745\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.5535 - acc: 0.3364 - val_loss: 10.7542 - val_acc: 0.3138\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.5025 - acc: 0.3336 - val_loss: 9.8508 - val_acc: 0.3684\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.1769 - acc: 0.3526 - val_loss: 10.2918 - val_acc: 0.3411\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.0796 - acc: 0.3584 - val_loss: 9.7977 - val_acc: 0.3755\n",
      "Epoch 6/30\n",
      "3948/3948 [==============================] - 0s - loss: 9.9483 - acc: 0.3683 - val_loss: 10.0228 - val_acc: 0.3593\n",
      "Epoch 7/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.0831 - acc: 0.3627 - val_loss: 10.1249 - val_acc: 0.3553\n",
      "Epoch 8/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.0087 - acc: 0.3645 - val_loss: 9.4695 - val_acc: 0.3907\n",
      "Epoch 9/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.1099 - acc: 0.3594 - val_loss: 9.8503 - val_acc: 0.3775\n",
      "Epoch 10/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.0312 - acc: 0.3670 - val_loss: 9.6701 - val_acc: 0.3806\n",
      "Epoch 11/30\n",
      "3948/3948 [==============================] - 0s - loss: 9.7067 - acc: 0.3835 - val_loss: 10.5184 - val_acc: 0.3310\n",
      "Epoch 12/30\n",
      "3948/3948 [==============================] - 0s - loss: 9.6166 - acc: 0.3873 - val_loss: 10.3677 - val_acc: 0.3360\n",
      "Epoch 13/30\n",
      "3948/3948 [==============================] - 0s - loss: 9.4684 - acc: 0.3959 - val_loss: 10.4076 - val_acc: 0.3370\n",
      "Epoch 14/30\n",
      "3948/3948 [==============================] - 0s - loss: 9.2683 - acc: 0.4119 - val_loss: 9.2147 - val_acc: 0.3998\n",
      "Epoch 15/30\n",
      "3948/3948 [==============================] - 0s - loss: 9.1925 - acc: 0.4126 - val_loss: 9.2826 - val_acc: 0.3968\n",
      "Epoch 16/30\n",
      "3948/3948 [==============================] - 0s - loss: 9.2545 - acc: 0.4098 - val_loss: 9.7750 - val_acc: 0.3543\n",
      "Epoch 17/30\n",
      "3948/3948 [==============================] - 0s - loss: 9.1115 - acc: 0.4134 - val_loss: 9.8391 - val_acc: 0.3543\n",
      "Epoch 18/30\n",
      "3948/3948 [==============================] - 0s - loss: 8.9700 - acc: 0.4268 - val_loss: 9.3792 - val_acc: 0.3796\n",
      "Epoch 19/30\n",
      "3948/3948 [==============================] - 0s - loss: 9.0951 - acc: 0.4111 - val_loss: 9.2149 - val_acc: 0.3947\n",
      "Epoch 20/30\n",
      "3948/3948 [==============================] - 0s - loss: 8.9549 - acc: 0.4195 - val_loss: 11.1554 - val_acc: 0.2672\n",
      "Epoch 21/30\n",
      "3948/3948 [==============================] - 0s - loss: 8.9935 - acc: 0.4177 - val_loss: 9.5647 - val_acc: 0.3583\n",
      "Epoch 22/30\n",
      "3948/3948 [==============================] - 0s - loss: 8.7345 - acc: 0.4238 - val_loss: 9.7580 - val_acc: 0.3117\n",
      "Epoch 23/30\n",
      "3948/3948 [==============================] - 0s - loss: 8.5653 - acc: 0.4283 - val_loss: 8.5064 - val_acc: 0.3340\n",
      "Epoch 24/30\n",
      "3948/3948 [==============================] - 0s - loss: 8.1684 - acc: 0.4276 - val_loss: 8.6412 - val_acc: 0.3138\n",
      "Epoch 25/30\n",
      "3948/3948 [==============================] - 0s - loss: 8.0385 - acc: 0.3987 - val_loss: 7.4396 - val_acc: 0.3543\n",
      "Epoch 26/30\n",
      "3948/3948 [==============================] - 0s - loss: 7.5595 - acc: 0.3863 - val_loss: 6.6177 - val_acc: 0.4028\n",
      "Epoch 27/30\n",
      "3948/3948 [==============================] - 0s - loss: 6.7711 - acc: 0.4225 - val_loss: 6.2577 - val_acc: 0.3674\n",
      "Epoch 28/30\n",
      "3948/3948 [==============================] - 0s - loss: 6.4903 - acc: 0.4271 - val_loss: 6.7033 - val_acc: 0.3441\n",
      "Epoch 29/30\n",
      "3948/3948 [==============================] - 0s - loss: 6.3643 - acc: 0.4230 - val_loss: 7.0316 - val_acc: 0.2885\n",
      "Epoch 30/30\n",
      "3948/3948 [==============================] - 0s - loss: 6.2832 - acc: 0.4248 - val_loss: 6.3734 - val_acc: 0.2915\n"
     ]
    }
   ],
   "source": [
    "model = dense_model()\n",
    "model.summary()\n",
    "\n",
    "hist = model.fit(mocap_head, Y, \n",
    "                 batch_size=100, nb_epoch=30, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 200, 18)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mocap_hand = []\n",
    "\n",
    "for ses_mod in data2:\n",
    "    x_hand = ses_mod['mocap_hand']\n",
    "    if(x_hand.shape != (200,18)):\n",
    "        x_hand = np.zeros((200,18))  \n",
    "    x_hand[np.isnan(x_hand)]=0\n",
    "    mocap_hand.append( x_hand )\n",
    "    \n",
    "mocap_hand = np.array(mocap_hand)\n",
    "mocap_hand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, return_sequences=False, input_shape=(200, 18)))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 256)               281600    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 315,012\n",
      "Trainable params: 315,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.3602 - acc: 0.3392 - val_loss: 1.4126 - val_acc: 0.2874\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.2965 - acc: 0.4012 - val_loss: 1.4367 - val_acc: 0.3219\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.2719 - acc: 0.4504 - val_loss: 1.4458 - val_acc: 0.3117\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.2541 - acc: 0.4650 - val_loss: 1.4950 - val_acc: 0.2702\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.2515 - acc: 0.4400 - val_loss: 1.4775 - val_acc: 0.2905\n",
      "Epoch 6/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.2361 - acc: 0.4635 - val_loss: 1.4288 - val_acc: 0.2864\n",
      "Epoch 7/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.2185 - acc: 0.4813 - val_loss: 1.4356 - val_acc: 0.3279\n",
      "Epoch 8/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.2108 - acc: 0.4891 - val_loss: 1.4357 - val_acc: 0.2702\n",
      "Epoch 9/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.2006 - acc: 0.4909 - val_loss: 1.4063 - val_acc: 0.2905\n",
      "Epoch 10/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1872 - acc: 0.5081 - val_loss: 1.4091 - val_acc: 0.3036\n",
      "Epoch 11/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1803 - acc: 0.5134 - val_loss: 1.4165 - val_acc: 0.3209\n",
      "Epoch 12/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1770 - acc: 0.5139 - val_loss: 1.4256 - val_acc: 0.3006\n",
      "Epoch 13/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1688 - acc: 0.5198 - val_loss: 1.4432 - val_acc: 0.3370\n",
      "Epoch 14/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1636 - acc: 0.5193 - val_loss: 1.4622 - val_acc: 0.3097\n",
      "Epoch 15/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1557 - acc: 0.5190 - val_loss: 1.4438 - val_acc: 0.3441\n",
      "Epoch 16/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1433 - acc: 0.5380 - val_loss: 1.5030 - val_acc: 0.3198\n",
      "Epoch 17/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1399 - acc: 0.5279 - val_loss: 1.4453 - val_acc: 0.3279\n",
      "Epoch 18/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1285 - acc: 0.5334 - val_loss: 1.4540 - val_acc: 0.3360\n",
      "Epoch 19/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1218 - acc: 0.5385 - val_loss: 1.4552 - val_acc: 0.3289\n",
      "Epoch 20/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1156 - acc: 0.5491 - val_loss: 1.4810 - val_acc: 0.3289\n",
      "Epoch 21/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1168 - acc: 0.5382 - val_loss: 1.4576 - val_acc: 0.3259\n",
      "Epoch 22/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1078 - acc: 0.5491 - val_loss: 1.4677 - val_acc: 0.2895\n",
      "Epoch 23/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1017 - acc: 0.5428 - val_loss: 1.4747 - val_acc: 0.3178\n",
      "Epoch 24/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1014 - acc: 0.5443 - val_loss: 1.5399 - val_acc: 0.2966\n",
      "Epoch 25/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.1014 - acc: 0.5476 - val_loss: 1.5787 - val_acc: 0.2773\n",
      "Epoch 26/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.0902 - acc: 0.5428 - val_loss: 1.4873 - val_acc: 0.3249\n",
      "Epoch 27/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.0849 - acc: 0.5474 - val_loss: 1.4787 - val_acc: 0.3158\n",
      "Epoch 28/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.0826 - acc: 0.5519 - val_loss: 1.4686 - val_acc: 0.2844\n",
      "Epoch 29/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.0838 - acc: 0.5547 - val_loss: 1.5132 - val_acc: 0.3300\n",
      "Epoch 30/30\n",
      "3948/3948 [==============================] - 12s - loss: 1.0735 - acc: 0.5603 - val_loss: 1.5380 - val_acc: 0.2763\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model()\n",
    "model.summary()\n",
    "\n",
    "hist = model.fit(mocap_hand, Y, \n",
    "                 batch_size=100, nb_epoch=30, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(200, 18)))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               921856    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 922,884\n",
      "Trainable params: 922,884\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3948/3948 [==============================] - 0s - loss: 10.6613 - acc: 0.3381 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 6/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 7/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 8/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 9/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 10/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 11/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 12/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 13/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 14/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 15/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 16/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 17/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 18/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 19/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 20/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 21/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 22/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 23/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 24/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 25/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 26/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 27/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 28/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 29/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n",
      "Epoch 30/30\n",
      "3948/3948 [==============================] - 0s - loss: 10.6556 - acc: 0.3389 - val_loss: 10.1337 - val_acc: 0.3694\n"
     ]
    }
   ],
   "source": [
    "model = dense_model()\n",
    "model.summary()\n",
    "\n",
    "hist = model.fit(mocap_hand, Y, \n",
    "                 batch_size=100, nb_epoch=30, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 200, 165)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mocap_rot = []\n",
    "\n",
    "for ses_mod in data2:\n",
    "    x_rot = ses_mod['mocap_rot']\n",
    "    if(x_rot.shape != (200,165)):\n",
    "        x_rot = np.zeros((200,165))  \n",
    "    x_rot[np.isnan(x_rot)]=0\n",
    "    mocap_rot.append( x_rot )\n",
    "    \n",
    "mocap_rot = np.array(mocap_rot)\n",
    "mocap_rot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(optimizer='Adadelta'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=(200, 165)))\n",
    "    model.add(LSTM(256, return_sequences=False))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 200, 512)          1388544   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,309,636\n",
      "Trainable params: 2,309,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      "3948/3948 [==============================] - 31s - loss: 1.3738 - acc: 0.3138 - val_loss: 1.3631 - val_acc: 0.3026\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.3583 - acc: 0.3300 - val_loss: 1.3247 - val_acc: 0.3694\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.3411 - acc: 0.3381 - val_loss: 1.3363 - val_acc: 0.3694\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.3323 - acc: 0.3333 - val_loss: 1.3459 - val_acc: 0.3573\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.3308 - acc: 0.3488 - val_loss: 1.3349 - val_acc: 0.2915\n",
      "Epoch 6/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.3299 - acc: 0.3430 - val_loss: 1.3339 - val_acc: 0.3522\n",
      "Epoch 7/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.3098 - acc: 0.3696 - val_loss: 1.5831 - val_acc: 0.2966\n",
      "Epoch 8/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.3221 - acc: 0.3587 - val_loss: 1.3852 - val_acc: 0.3482\n",
      "Epoch 9/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.3139 - acc: 0.3703 - val_loss: 1.2544 - val_acc: 0.4514\n",
      "Epoch 10/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.3006 - acc: 0.3777 - val_loss: 1.3493 - val_acc: 0.3806\n",
      "Epoch 11/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.2867 - acc: 0.3873 - val_loss: 1.2884 - val_acc: 0.3897\n",
      "Epoch 12/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.2874 - acc: 0.3964 - val_loss: 1.2623 - val_acc: 0.4514\n",
      "Epoch 13/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.2373 - acc: 0.4177 - val_loss: 1.3151 - val_acc: 0.3968\n",
      "Epoch 14/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.2480 - acc: 0.4063 - val_loss: 1.1884 - val_acc: 0.4899\n",
      "Epoch 15/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.2466 - acc: 0.4040 - val_loss: 1.2471 - val_acc: 0.3846\n",
      "Epoch 16/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.2341 - acc: 0.4154 - val_loss: 1.2246 - val_acc: 0.3988\n",
      "Epoch 17/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.2194 - acc: 0.4205 - val_loss: 1.3235 - val_acc: 0.3664\n",
      "Epoch 18/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.2273 - acc: 0.4205 - val_loss: 1.3308 - val_acc: 0.3664\n",
      "Epoch 19/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.2223 - acc: 0.4212 - val_loss: 1.3593 - val_acc: 0.4018\n",
      "Epoch 20/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.2082 - acc: 0.4420 - val_loss: 1.2611 - val_acc: 0.4808\n",
      "Epoch 21/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.1948 - acc: 0.4400 - val_loss: 1.2648 - val_acc: 0.4049\n",
      "Epoch 22/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.2050 - acc: 0.4397 - val_loss: 1.2341 - val_acc: 0.4504\n",
      "Epoch 23/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.2050 - acc: 0.4369 - val_loss: 1.2724 - val_acc: 0.4676\n",
      "Epoch 24/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.1831 - acc: 0.4562 - val_loss: 1.2477 - val_acc: 0.4848\n",
      "Epoch 25/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.1782 - acc: 0.4567 - val_loss: 1.2830 - val_acc: 0.4484\n",
      "Epoch 26/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.1901 - acc: 0.4471 - val_loss: 1.3052 - val_acc: 0.3957\n",
      "Epoch 27/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.1968 - acc: 0.4314 - val_loss: 2.2823 - val_acc: 0.2611\n",
      "Epoch 28/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.1956 - acc: 0.4496 - val_loss: 1.2155 - val_acc: 0.3968\n",
      "Epoch 29/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.1782 - acc: 0.4516 - val_loss: 1.3605 - val_acc: 0.3836\n",
      "Epoch 30/30\n",
      "3948/3948 [==============================] - 30s - loss: 1.1653 - acc: 0.4587 - val_loss: 1.2666 - val_acc: 0.4332\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model()\n",
    "model.summary()\n",
    "\n",
    "hist = model.fit(mocap_rot, Y, \n",
    "                 batch_size=100, nb_epoch=30, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3948/3948 [==============================] - 30s - loss: 1.1814 - acc: 0.4473 - val_loss: 1.2605 - val_acc: 0.4079\n",
      "Epoch 2/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1952 - acc: 0.4402 - val_loss: 1.4706 - val_acc: 0.3128\n",
      "Epoch 3/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1538 - acc: 0.4709 - val_loss: 1.2523 - val_acc: 0.3937\n",
      "Epoch 4/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1612 - acc: 0.4633 - val_loss: 1.4993 - val_acc: 0.3381\n",
      "Epoch 5/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1688 - acc: 0.4694 - val_loss: 1.3648 - val_acc: 0.4221\n",
      "Epoch 6/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1780 - acc: 0.4663 - val_loss: 1.2808 - val_acc: 0.3998\n",
      "Epoch 7/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1479 - acc: 0.4739 - val_loss: 1.2455 - val_acc: 0.4514\n",
      "Epoch 8/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1294 - acc: 0.4742 - val_loss: 1.5512 - val_acc: 0.3907\n",
      "Epoch 9/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1536 - acc: 0.4630 - val_loss: 1.2632 - val_acc: 0.4059\n",
      "Epoch 10/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1739 - acc: 0.4585 - val_loss: 1.3206 - val_acc: 0.4059\n",
      "Epoch 11/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1455 - acc: 0.4688 - val_loss: 1.8851 - val_acc: 0.3026\n",
      "Epoch 12/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1637 - acc: 0.4529 - val_loss: 1.3308 - val_acc: 0.4140\n",
      "Epoch 13/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1355 - acc: 0.4744 - val_loss: 1.3514 - val_acc: 0.3856\n",
      "Epoch 14/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1454 - acc: 0.4699 - val_loss: 1.2389 - val_acc: 0.4221\n",
      "Epoch 15/15\n",
      "3948/3948 [==============================] - 30s - loss: 1.1470 - acc: 0.4694 - val_loss: 1.2747 - val_acc: 0.4494\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hist = model.fit(mocap_rot, Y, \n",
    "                 batch_size=100, nb_epoch=15, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_conv(optimizer='Adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 165, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, input_shape=(200, 165,..., padding=\"same\", strides=(2, 2))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"same\", strides=(2, 2))`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"same\", strides=(2, 2))`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", strides=(2, 2))`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", strides=(2, 2))`\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 100, 83, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 100, 83, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 100, 83, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 50, 42, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 50, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 50, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 25, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 25, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 25, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 13, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 13, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 13, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               1376512   \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,654,724\n",
      "Trainable params: 1,654,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/50\n",
      "3948/3948 [==============================] - 7s - loss: 2.2792 - acc: 0.2948 - val_loss: 1.3676 - val_acc: 0.3694\n",
      "Epoch 2/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.3675 - acc: 0.3399 - val_loss: 1.3664 - val_acc: 0.3694\n",
      "Epoch 3/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.3610 - acc: 0.3389 - val_loss: 1.3563 - val_acc: 0.3694\n",
      "Epoch 4/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.3362 - acc: 0.3463 - val_loss: 1.2638 - val_acc: 0.4858\n",
      "Epoch 5/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2923 - acc: 0.3832 - val_loss: 1.4845 - val_acc: 0.4362\n",
      "Epoch 6/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2382 - acc: 0.4058 - val_loss: 1.8957 - val_acc: 0.3968\n",
      "Epoch 7/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2263 - acc: 0.4187 - val_loss: 1.7246 - val_acc: 0.3512\n",
      "Epoch 8/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2111 - acc: 0.4235 - val_loss: 1.5867 - val_acc: 0.4140\n",
      "Epoch 9/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1906 - acc: 0.4276 - val_loss: 2.3048 - val_acc: 0.3957\n",
      "Epoch 10/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1882 - acc: 0.4303 - val_loss: 1.6373 - val_acc: 0.4170\n",
      "Epoch 11/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1733 - acc: 0.4415 - val_loss: 1.3014 - val_acc: 0.4545\n",
      "Epoch 12/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1614 - acc: 0.4531 - val_loss: 1.5691 - val_acc: 0.3725\n",
      "Epoch 13/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1526 - acc: 0.4635 - val_loss: 2.0834 - val_acc: 0.3735\n",
      "Epoch 14/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1649 - acc: 0.4597 - val_loss: 1.7344 - val_acc: 0.3846\n",
      "Epoch 15/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1400 - acc: 0.4643 - val_loss: 2.0115 - val_acc: 0.3796\n",
      "Epoch 16/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1258 - acc: 0.4835 - val_loss: 1.7595 - val_acc: 0.3775\n",
      "Epoch 17/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1197 - acc: 0.4838 - val_loss: 1.8847 - val_acc: 0.3836\n",
      "Epoch 18/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1143 - acc: 0.4949 - val_loss: 1.7786 - val_acc: 0.3725\n",
      "Epoch 19/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1100 - acc: 0.4891 - val_loss: 1.6361 - val_acc: 0.4291\n",
      "Epoch 20/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.0764 - acc: 0.5041 - val_loss: 1.9004 - val_acc: 0.4119\n",
      "Epoch 21/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.0598 - acc: 0.5203 - val_loss: 1.9201 - val_acc: 0.3775\n",
      "Epoch 22/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.0860 - acc: 0.4980 - val_loss: 1.5509 - val_acc: 0.4079\n",
      "Epoch 23/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.0475 - acc: 0.5289 - val_loss: 1.7467 - val_acc: 0.4150\n",
      "Epoch 24/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.0582 - acc: 0.5180 - val_loss: 2.0738 - val_acc: 0.3796\n",
      "Epoch 25/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.0296 - acc: 0.5428 - val_loss: 1.8490 - val_acc: 0.3968\n",
      "Epoch 26/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.0227 - acc: 0.5360 - val_loss: 2.0122 - val_acc: 0.4049\n",
      "Epoch 27/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.0176 - acc: 0.5484 - val_loss: 2.0722 - val_acc: 0.4028\n",
      "Epoch 28/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.0230 - acc: 0.5365 - val_loss: 2.1523 - val_acc: 0.4049\n",
      "Epoch 29/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9915 - acc: 0.5600 - val_loss: 2.1706 - val_acc: 0.4332\n",
      "Epoch 30/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9969 - acc: 0.5504 - val_loss: 2.2911 - val_acc: 0.3937\n",
      "Epoch 31/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9898 - acc: 0.5557 - val_loss: 2.1422 - val_acc: 0.4423\n",
      "Epoch 32/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9724 - acc: 0.5646 - val_loss: 2.6338 - val_acc: 0.4291\n",
      "Epoch 33/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9726 - acc: 0.5712 - val_loss: 2.0438 - val_acc: 0.4575\n",
      "Epoch 34/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9667 - acc: 0.5628 - val_loss: 2.0142 - val_acc: 0.4231\n",
      "Epoch 35/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9563 - acc: 0.5724 - val_loss: 2.2799 - val_acc: 0.4251\n",
      "Epoch 36/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9541 - acc: 0.5778 - val_loss: 2.2215 - val_acc: 0.4109\n",
      "Epoch 37/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9304 - acc: 0.5899 - val_loss: 2.3020 - val_acc: 0.4089\n",
      "Epoch 38/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9425 - acc: 0.5775 - val_loss: 2.1923 - val_acc: 0.4383\n",
      "Epoch 39/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9175 - acc: 0.5942 - val_loss: 2.3635 - val_acc: 0.4211\n",
      "Epoch 40/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9163 - acc: 0.5965 - val_loss: 2.2860 - val_acc: 0.4271\n",
      "Epoch 41/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.8797 - acc: 0.6107 - val_loss: 2.4818 - val_acc: 0.4423\n",
      "Epoch 42/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.9145 - acc: 0.5922 - val_loss: 2.1346 - val_acc: 0.4585\n",
      "Epoch 43/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.8996 - acc: 0.5988 - val_loss: 2.2166 - val_acc: 0.4524\n",
      "Epoch 44/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.8657 - acc: 0.6183 - val_loss: 2.4720 - val_acc: 0.4089\n",
      "Epoch 45/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.8636 - acc: 0.6256 - val_loss: 2.6302 - val_acc: 0.4059\n",
      "Epoch 46/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.8607 - acc: 0.6294 - val_loss: 2.1549 - val_acc: 0.4302\n",
      "Epoch 47/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.8478 - acc: 0.6388 - val_loss: 2.5526 - val_acc: 0.4190\n",
      "Epoch 48/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.8661 - acc: 0.6127 - val_loss: 2.3899 - val_acc: 0.4281\n",
      "Epoch 49/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.8428 - acc: 0.6365 - val_loss: 2.2154 - val_acc: 0.4302\n",
      "Epoch 50/50\n",
      "3948/3948 [==============================] - 6s - loss: 0.8263 - acc: 0.6401 - val_loss: 2.0101 - val_acc: 0.4575\n"
     ]
    }
   ],
   "source": [
    "model = simple_conv()\n",
    "model.summary()\n",
    "\n",
    "mocap_rot_re = mocap_rot.reshape(-1,200,165,1)\n",
    "\n",
    "hist = model.fit(mocap_rot_re, Y, \n",
    "                 batch_size=100, nb_epoch=50, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_conv2(optimizer='SGD'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 165, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, input_shape=(200, 165,..., padding=\"same\", strides=(2, 2))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"same\", strides=(2, 2))`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"same\", strides=(2, 2))`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", strides=(2, 2))`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 100, 83, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 100, 83, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 100, 83, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 50, 42, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 50, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 50, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 25, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 25, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 25, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 13, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 13, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 18304)             0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1024)              18744320  \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 19,137,348\n",
      "Trainable params: 19,137,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/50\n",
      "3948/3948 [==============================] - 7s - loss: 2.0693 - acc: 0.2910 - val_loss: 1.3820 - val_acc: 0.2338\n",
      "Epoch 2/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.3772 - acc: 0.3133 - val_loss: 1.3797 - val_acc: 0.3553\n",
      "Epoch 3/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.3674 - acc: 0.3280 - val_loss: 1.3770 - val_acc: 0.3553\n",
      "Epoch 4/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.3670 - acc: 0.3290 - val_loss: 1.3721 - val_acc: 0.4008\n",
      "Epoch 5/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.3615 - acc: 0.3316 - val_loss: 1.3693 - val_acc: 0.3796\n",
      "Epoch 6/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.3523 - acc: 0.3402 - val_loss: 1.3579 - val_acc: 0.3947\n",
      "Epoch 7/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.3459 - acc: 0.3354 - val_loss: 1.3210 - val_acc: 0.4626\n",
      "Epoch 8/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.3316 - acc: 0.3544 - val_loss: 1.3626 - val_acc: 0.2844\n",
      "Epoch 9/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.3194 - acc: 0.3713 - val_loss: 1.2776 - val_acc: 0.3917\n",
      "Epoch 10/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.3048 - acc: 0.3789 - val_loss: 1.2408 - val_acc: 0.4939\n",
      "Epoch 11/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2925 - acc: 0.3779 - val_loss: 1.4708 - val_acc: 0.2611\n",
      "Epoch 12/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2840 - acc: 0.3883 - val_loss: 1.2224 - val_acc: 0.3846\n",
      "Epoch 13/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2677 - acc: 0.4015 - val_loss: 1.3917 - val_acc: 0.2874\n",
      "Epoch 14/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2592 - acc: 0.3997 - val_loss: 1.6013 - val_acc: 0.2753\n",
      "Epoch 15/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2534 - acc: 0.3967 - val_loss: 1.2792 - val_acc: 0.3937\n",
      "Epoch 16/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2508 - acc: 0.4015 - val_loss: 1.2101 - val_acc: 0.3988\n",
      "Epoch 17/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2414 - acc: 0.4007 - val_loss: 1.1955 - val_acc: 0.4281\n",
      "Epoch 18/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2305 - acc: 0.4101 - val_loss: 1.2779 - val_acc: 0.4008\n",
      "Epoch 19/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2444 - acc: 0.4116 - val_loss: 1.3666 - val_acc: 0.3553\n",
      "Epoch 20/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2170 - acc: 0.4189 - val_loss: 1.3107 - val_acc: 0.3856\n",
      "Epoch 21/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2059 - acc: 0.4253 - val_loss: 1.3333 - val_acc: 0.3796\n",
      "Epoch 22/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.2095 - acc: 0.4268 - val_loss: 1.3809 - val_acc: 0.3897\n",
      "Epoch 23/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1941 - acc: 0.4352 - val_loss: 1.4190 - val_acc: 0.4069\n",
      "Epoch 24/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1912 - acc: 0.4422 - val_loss: 1.9471 - val_acc: 0.3067\n",
      "Epoch 25/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1929 - acc: 0.4319 - val_loss: 1.2676 - val_acc: 0.4028\n",
      "Epoch 26/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1829 - acc: 0.4504 - val_loss: 1.3137 - val_acc: 0.4119\n",
      "Epoch 27/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1803 - acc: 0.4443 - val_loss: 1.2394 - val_acc: 0.3816\n",
      "Epoch 28/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1812 - acc: 0.4276 - val_loss: 1.3348 - val_acc: 0.3927\n",
      "Epoch 29/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1812 - acc: 0.4364 - val_loss: 1.2820 - val_acc: 0.3927\n",
      "Epoch 30/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1669 - acc: 0.4590 - val_loss: 1.4781 - val_acc: 0.3907\n",
      "Epoch 31/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1752 - acc: 0.4519 - val_loss: 1.3245 - val_acc: 0.4028\n",
      "Epoch 32/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1564 - acc: 0.4618 - val_loss: 1.4480 - val_acc: 0.3745\n",
      "Epoch 33/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1592 - acc: 0.4628 - val_loss: 1.4142 - val_acc: 0.4352\n",
      "Epoch 34/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1571 - acc: 0.4615 - val_loss: 1.3540 - val_acc: 0.3887\n",
      "Epoch 35/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1519 - acc: 0.4688 - val_loss: 1.5050 - val_acc: 0.4130\n",
      "Epoch 36/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1431 - acc: 0.4790 - val_loss: 1.5490 - val_acc: 0.4059\n",
      "Epoch 37/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1375 - acc: 0.4711 - val_loss: 1.6287 - val_acc: 0.3917\n",
      "Epoch 38/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1490 - acc: 0.4757 - val_loss: 1.8286 - val_acc: 0.3684\n",
      "Epoch 39/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1522 - acc: 0.4709 - val_loss: 1.8583 - val_acc: 0.3725\n",
      "Epoch 40/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1364 - acc: 0.4820 - val_loss: 1.4329 - val_acc: 0.4049\n",
      "Epoch 41/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1365 - acc: 0.4759 - val_loss: 1.5637 - val_acc: 0.3937\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3948/3948 [==============================] - 6s - loss: 1.1454 - acc: 0.4688 - val_loss: 1.4471 - val_acc: 0.4079\n",
      "Epoch 43/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1270 - acc: 0.4807 - val_loss: 1.4061 - val_acc: 0.4393\n",
      "Epoch 44/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1202 - acc: 0.4891 - val_loss: 1.7763 - val_acc: 0.3937\n",
      "Epoch 45/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1185 - acc: 0.4871 - val_loss: 1.3527 - val_acc: 0.4038\n",
      "Epoch 46/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1254 - acc: 0.4777 - val_loss: 1.5836 - val_acc: 0.4079\n",
      "Epoch 47/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1094 - acc: 0.4848 - val_loss: 1.3795 - val_acc: 0.3836\n",
      "Epoch 48/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1163 - acc: 0.4845 - val_loss: 1.4710 - val_acc: 0.3927\n",
      "Epoch 49/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1077 - acc: 0.4843 - val_loss: 1.6064 - val_acc: 0.4130\n",
      "Epoch 50/50\n",
      "3948/3948 [==============================] - 6s - loss: 1.1172 - acc: 0.4896 - val_loss: 1.4997 - val_acc: 0.4261\n"
     ]
    }
   ],
   "source": [
    "model = simple_conv2()\n",
    "model.summary()\n",
    "\n",
    "mocap_rot_re = mocap_rot.reshape(-1,200,165,1)\n",
    "\n",
    "hist = model.fit(mocap_rot_re, Y, \n",
    "                 batch_size=100, nb_epoch=50, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 200, 189, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mocap = []\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['mocap_head']\n",
    "    if(x_head.shape != (200,18)):\n",
    "        x_head = np.zeros((200,18))   \n",
    "    x_head[np.isnan(x_head)]=0\n",
    "    x_hand = ses_mod['mocap_hand']\n",
    "    if(x_hand.shape != (200,6)):\n",
    "        x_hand = np.zeros((200,6))   \n",
    "    x_hand[np.isnan(x_hand)]=0\n",
    "    x_rot = ses_mod['mocap_rot']\n",
    "    if(x_rot.shape != (200,165)):\n",
    "        x_rot = np.zeros((200,165))   \n",
    "    x_rot[np.isnan(x_rot)]=0\n",
    "    x_mocap = np.concatenate((x_head, x_hand), axis=1)\n",
    "    x_mocap = np.concatenate((x_mocap, x_rot), axis=1)\n",
    "    x_train_mocap.append( x_mocap )\n",
    "    \n",
    "x_train_mocap = np.array(x_train_mocap)\n",
    "x_train_mocap = x_train_mocap.reshape(-1,200,189,1)\n",
    "x_train_mocap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_conv3(optimizer='SGD'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 189, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, input_shape=(200, 189,..., padding=\"same\", strides=(2, 2))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"same\", strides=(2, 2))`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, padding=\"same\", strides=(2, 2))`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, padding=\"same\", strides=(2, 2))`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 100, 95, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 50, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 25, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 13, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 19968)             0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1024)              20448256  \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 20,841,284\n",
      "Trainable params: 20,841,284\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/50\n",
      "3948/3948 [==============================] - 9s - loss: 12.6041 - acc: 0.2026 - val_loss: 11.8788 - val_acc: 0.2611\n",
      "Epoch 2/50\n",
      "3948/3948 [==============================] - 7s - loss: 12.9214 - acc: 0.1983 - val_loss: 11.8788 - val_acc: 0.2611\n",
      "Epoch 3/50\n",
      "3948/3948 [==============================] - 7s - loss: 12.9214 - acc: 0.1983 - val_loss: 11.8788 - val_acc: 0.2611\n",
      "Epoch 4/50\n",
      "3948/3948 [==============================] - 7s - loss: 12.9214 - acc: 0.1983 - val_loss: 11.8788 - val_acc: 0.2611\n",
      "Epoch 5/50\n",
      "3948/3948 [==============================] - 7s - loss: 12.9212 - acc: 0.1983 - val_loss: 11.8771 - val_acc: 0.2611\n",
      "Epoch 6/50\n",
      "3948/3948 [==============================] - 7s - loss: 12.9214 - acc: 0.1983 - val_loss: 11.8771 - val_acc: 0.2611\n",
      "Epoch 7/50\n",
      "3948/3948 [==============================] - 7s - loss: 12.9193 - acc: 0.1983 - val_loss: 11.8633 - val_acc: 0.2611\n",
      "Epoch 8/50\n",
      "3948/3948 [==============================] - 7s - loss: 8.2308 - acc: 0.2404 - val_loss: 1.3859 - val_acc: 0.3381\n",
      "Epoch 9/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.3818 - acc: 0.3057 - val_loss: 1.3930 - val_acc: 0.2551\n",
      "Epoch 10/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.3709 - acc: 0.3283 - val_loss: 1.3875 - val_acc: 0.2551\n",
      "Epoch 11/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.3678 - acc: 0.3278 - val_loss: 1.3766 - val_acc: 0.3563\n",
      "Epoch 12/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.3625 - acc: 0.3316 - val_loss: 1.3690 - val_acc: 0.3694\n",
      "Epoch 13/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.3638 - acc: 0.3285 - val_loss: 1.3600 - val_acc: 0.3694\n",
      "Epoch 14/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.3535 - acc: 0.3333 - val_loss: 1.3504 - val_acc: 0.3968\n",
      "Epoch 15/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.3464 - acc: 0.3389 - val_loss: 1.3409 - val_acc: 0.4706\n",
      "Epoch 16/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.3323 - acc: 0.3503 - val_loss: 1.2935 - val_acc: 0.4666\n",
      "Epoch 17/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.3254 - acc: 0.3609 - val_loss: 1.2643 - val_acc: 0.4980\n",
      "Epoch 18/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.3149 - acc: 0.3706 - val_loss: 1.2450 - val_acc: 0.4889\n",
      "Epoch 19/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.3131 - acc: 0.3670 - val_loss: 1.3481 - val_acc: 0.2753\n",
      "Epoch 20/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.2860 - acc: 0.3954 - val_loss: 1.3225 - val_acc: 0.2874\n",
      "Epoch 21/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.2760 - acc: 0.3868 - val_loss: 1.2988 - val_acc: 0.4717\n",
      "Epoch 22/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.2661 - acc: 0.3949 - val_loss: 1.1848 - val_acc: 0.4909\n",
      "Epoch 23/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.2533 - acc: 0.3992 - val_loss: 1.5493 - val_acc: 0.2642\n",
      "Epoch 24/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.2437 - acc: 0.4032 - val_loss: 1.4508 - val_acc: 0.2794\n",
      "Epoch 25/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.2240 - acc: 0.4192 - val_loss: 1.2395 - val_acc: 0.4413\n",
      "Epoch 26/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.2197 - acc: 0.4258 - val_loss: 1.3876 - val_acc: 0.2996\n",
      "Epoch 27/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.2129 - acc: 0.4260 - val_loss: 1.2895 - val_acc: 0.3472\n",
      "Epoch 28/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.2089 - acc: 0.4349 - val_loss: 1.2309 - val_acc: 0.4696\n",
      "Epoch 29/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.2031 - acc: 0.4392 - val_loss: 1.2433 - val_acc: 0.4889\n",
      "Epoch 30/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1924 - acc: 0.4412 - val_loss: 1.1743 - val_acc: 0.5101\n",
      "Epoch 31/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.2036 - acc: 0.4319 - val_loss: 1.2917 - val_acc: 0.3745\n",
      "Epoch 32/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1880 - acc: 0.4428 - val_loss: 1.3973 - val_acc: 0.4241\n",
      "Epoch 33/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1760 - acc: 0.4549 - val_loss: 1.1600 - val_acc: 0.5111\n",
      "Epoch 34/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1751 - acc: 0.4557 - val_loss: 1.2310 - val_acc: 0.4119\n",
      "Epoch 35/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1793 - acc: 0.4486 - val_loss: 1.3496 - val_acc: 0.4170\n",
      "Epoch 36/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1735 - acc: 0.4539 - val_loss: 1.2249 - val_acc: 0.4757\n",
      "Epoch 37/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1609 - acc: 0.4569 - val_loss: 1.1925 - val_acc: 0.4939\n",
      "Epoch 38/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1578 - acc: 0.4607 - val_loss: 1.2696 - val_acc: 0.3998\n",
      "Epoch 39/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1599 - acc: 0.4688 - val_loss: 1.4266 - val_acc: 0.4008\n",
      "Epoch 40/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1697 - acc: 0.4549 - val_loss: 1.2184 - val_acc: 0.4322\n",
      "Epoch 41/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1747 - acc: 0.4488 - val_loss: 1.2843 - val_acc: 0.4909\n",
      "Epoch 42/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1557 - acc: 0.4633 - val_loss: 1.2629 - val_acc: 0.3927\n",
      "Epoch 43/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1514 - acc: 0.4681 - val_loss: 1.3454 - val_acc: 0.3846\n",
      "Epoch 44/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1462 - acc: 0.4833 - val_loss: 1.4319 - val_acc: 0.3775\n",
      "Epoch 45/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1495 - acc: 0.4704 - val_loss: 1.5560 - val_acc: 0.4312\n",
      "Epoch 46/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1414 - acc: 0.4742 - val_loss: 1.3472 - val_acc: 0.3978\n",
      "Epoch 47/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1454 - acc: 0.4643 - val_loss: 1.2161 - val_acc: 0.3826\n",
      "Epoch 48/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1322 - acc: 0.4800 - val_loss: 1.2772 - val_acc: 0.4079\n",
      "Epoch 49/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1334 - acc: 0.4777 - val_loss: 1.3877 - val_acc: 0.3998\n",
      "Epoch 50/50\n",
      "3948/3948 [==============================] - 7s - loss: 1.1467 - acc: 0.4714 - val_loss: 1.3643 - val_acc: 0.4099\n"
     ]
    }
   ],
   "source": [
    "model = simple_conv3()\n",
    "model.summary()\n",
    "\n",
    "\n",
    "hist = model.fit(x_train_mocap, Y, \n",
    "                 batch_size=100, nb_epoch=50, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
