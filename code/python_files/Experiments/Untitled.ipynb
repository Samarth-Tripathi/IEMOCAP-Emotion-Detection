{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import wave\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold, train_test_split\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import LSTM, Input\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utilities.utils import *\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_feat = 34\n",
    "nb_class = 4\n",
    "nb_epoch = 80\n",
    "\n",
    "optimizer = 'Adadelta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "available_emotions            ['ang' 'exc' 'neu' 'sad']                                             \n",
      "conf_matrix_prefix            iemocap                                                               \n",
      "framerate                     16000                                                                 \n",
      "path_to_data                  /home/samarth/sail.usc.edu/databases/iemocap/small/emotion_recognition\n",
      "path_to_features              /home/samarth/sail.usc.edu/databases/iemocap/small/emotion_recognition\n",
      "sessions                      ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']          \n",
      "types                         {1: <class 'numpy.int8'>, 2: <class 'numpy.int16'>, 4: <class 'numpy.i\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "params = Constants()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iemocap_transcriptions(params=Constants()):\n",
    "    data = []\n",
    "    for session in params.sessions:\n",
    "        path_to_wav = params.path_to_data + session + '/dialog/wav/'\n",
    "        path_to_emotions = params.path_to_data + session + '/dialog/EmoEvaluation/'\n",
    "        path_to_transcriptions = params.path_to_data + session + '/dialog/transcriptions/'\n",
    "\n",
    "        files = os.listdir(path_to_wav)\n",
    "        files = [f[:-4] for f in files if f.endswith(\".wav\")]\n",
    "        for f in files:           \n",
    "            transcriptions = get_transcriptions(path_to_transcriptions, f + '.txt')\n",
    "            emotions = get_emotions(path_to_emotions, f + '.txt')\n",
    "\n",
    "            for ie, e in enumerate(emotions):\n",
    "                e.pop(\"left\", None)\n",
    "                e.pop(\"right\", None)\n",
    "                e['transcription'] = transcriptions[e['id']]\n",
    "                if e['emotion'] in params.available_emotions:\n",
    "                    data.append(e)\n",
    "    sort_key = get_field(data, \"id\")\n",
    "    return np.array(data)[np.argsort(sort_key)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_iemocap_transcriptions(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537\n"
     ]
    }
   ],
   "source": [
    "data[100]['transcription']\n",
    "\n",
    "text = []\n",
    "\n",
    "max_seq_len =0\n",
    "\n",
    "for ses_mod in data:\n",
    "    max_seq_len = max(max_seq_len, len(ses_mod['transcription']))\n",
    "    text.append(ses_mod['transcription'])\n",
    "    \n",
    "print (str(max_seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is this a joke?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=[]\n",
    "for ses_mod in data:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4936"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import random\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Merge, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution1D, GRU, MaxPooling1D\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "#from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "token_tr_X = tokenizer.texts_to_sequences(text)\n",
    "\n",
    "\n",
    "x_train = sequence.pad_sequences(token_tr_X, maxlen=MAX_SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,   16,   19,    6, 1061], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2736 unique tokens\n",
      "/home/samarth/sail.usc.edu/databases/iemocap/small/emotion_recognition-master/code/utilities/../../data/sessions/../glove.42B.300d.txt\n",
      "G Word embeddings: 1917494\n",
      "G Null word embeddings: 90\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "file_loc = params.path_to_data + '../glove.42B.300d.txt'\n",
    "\n",
    "print (file_loc)\n",
    "\n",
    "gembeddings_index = {}\n",
    "with codecs.open(file_loc, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        gembedding = np.asarray(values[1:], dtype='float32')\n",
    "        gembeddings_index[word] = gembedding\n",
    "#\n",
    "f.close()\n",
    "print('G Word embeddings:', len(gembeddings_index))\n",
    "\n",
    "nb_words = len(word_index) +1\n",
    "g_word_embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    gembedding_vector = gembeddings_index.get(word)\n",
    "    if gembedding_vector is not None:\n",
    "        g_word_embedding_matrix[i] = gembedding_vector\n",
    "        \n",
    "print('G Null word embeddings: %d' % np.sum(np.sum(g_word_embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 500, 256)          230656    \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 500, 128)          98432     \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 500, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 500, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 256)               4096256   \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 5,278,288\n",
      "Trainable params: 5,278,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, padding=\"same\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "model.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution1D(128, 3, border_mode='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution1D(64, 3, border_mode='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution1D(32, 3, border_mode='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model.summary()\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      " 128/3948 [..............................] - ETA: 4s - loss: 0.0929 - acc: 0.9531"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1585 - acc: 0.9359 - val_loss: 2.2693 - val_acc: 0.6204\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1769 - acc: 0.9283 - val_loss: 2.0349 - val_acc: 0.6204\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1634 - acc: 0.9296 - val_loss: 2.4459 - val_acc: 0.6204\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1642 - acc: 0.9316 - val_loss: 2.2937 - val_acc: 0.6255\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1681 - acc: 0.9319 - val_loss: 2.2685 - val_acc: 0.6174\n",
      "Epoch 6/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1702 - acc: 0.9296 - val_loss: 2.2073 - val_acc: 0.6215\n",
      "Epoch 7/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1612 - acc: 0.9301 - val_loss: 2.3522 - val_acc: 0.5860\n",
      "Epoch 8/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1485 - acc: 0.9329 - val_loss: 2.4672 - val_acc: 0.6255\n",
      "Epoch 9/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1403 - acc: 0.9402 - val_loss: 2.5071 - val_acc: 0.6366\n",
      "Epoch 10/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1527 - acc: 0.9334 - val_loss: 2.2634 - val_acc: 0.6083\n",
      "Epoch 11/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1614 - acc: 0.9397 - val_loss: 2.2735 - val_acc: 0.6336\n",
      "Epoch 12/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1562 - acc: 0.9379 - val_loss: 2.2370 - val_acc: 0.6377\n",
      "Epoch 13/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1384 - acc: 0.9390 - val_loss: 2.4164 - val_acc: 0.6346\n",
      "Epoch 14/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1489 - acc: 0.9397 - val_loss: 2.2512 - val_acc: 0.6154\n",
      "Epoch 15/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1454 - acc: 0.9374 - val_loss: 2.3052 - val_acc: 0.6316\n",
      "Epoch 16/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1384 - acc: 0.9402 - val_loss: 2.5407 - val_acc: 0.6296\n",
      "Epoch 17/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1382 - acc: 0.9372 - val_loss: 2.5962 - val_acc: 0.6407\n",
      "Epoch 18/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1403 - acc: 0.9384 - val_loss: 2.5724 - val_acc: 0.6285\n",
      "Epoch 19/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1376 - acc: 0.9384 - val_loss: 2.5074 - val_acc: 0.6397\n",
      "Epoch 20/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1357 - acc: 0.9390 - val_loss: 2.6570 - val_acc: 0.6488\n",
      "Epoch 21/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1354 - acc: 0.9407 - val_loss: 2.6663 - val_acc: 0.6336\n",
      "Epoch 22/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1339 - acc: 0.9397 - val_loss: 2.6435 - val_acc: 0.6356\n",
      "Epoch 23/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1272 - acc: 0.9430 - val_loss: 2.7781 - val_acc: 0.6154\n",
      "Epoch 24/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1275 - acc: 0.9415 - val_loss: 2.8843 - val_acc: 0.6377\n",
      "Epoch 25/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1285 - acc: 0.9422 - val_loss: 2.7946 - val_acc: 0.6255\n",
      "Epoch 26/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1435 - acc: 0.9384 - val_loss: 2.5729 - val_acc: 0.6366\n",
      "Epoch 27/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1392 - acc: 0.9367 - val_loss: 2.6370 - val_acc: 0.6366\n",
      "Epoch 28/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1284 - acc: 0.9435 - val_loss: 2.7466 - val_acc: 0.6427\n",
      "Epoch 29/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1336 - acc: 0.9357 - val_loss: 2.7786 - val_acc: 0.6154\n",
      "Epoch 30/30\n",
      "3948/3948 [==============================] - 5s 1ms/step - loss: 0.1505 - acc: 0.9357 - val_loss: 2.6965 - val_acc: 0.6002\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, Y, \n",
    "                 batch_size=batch_size, nb_epoch=30, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
