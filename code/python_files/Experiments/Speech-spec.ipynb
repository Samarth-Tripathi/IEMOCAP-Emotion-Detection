{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import wave\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import LSTM, Input, Flatten, Merge, Embedding, Convolution1D,Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from scipy import signal\n",
    "\n",
    "from features import *\n",
    "from helper import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "code_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n",
    "data_path = code_path + \"/../data/sessions/\"\n",
    "sessions = ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']\n",
    "framerate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(data_path + '/../'+'data_collected.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 300)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = 16e3\n",
    "f, t, Sxx = signal.spectrogram(data2[1000]['signal'], fs,nperseg=400)\n",
    "Sxx, _ = pad_sequence_into_array(Sxx, maxlen=300)\n",
    "Sxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4936, 201, 300)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_speech = []\n",
    "fs = 16e3\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_speech = ses_mod['signal']\n",
    "    f, t, Sxx = signal.spectrogram(x_speech, fs, nperseg=400)\n",
    "    Sxx, _ = pad_sequence_into_array(Sxx, maxlen=300)\n",
    "    x_train_speech.append(Sxx)\n",
    "    counter+=1\n",
    "    if(counter%100==0):\n",
    "        print(counter)\n",
    "    \n",
    "x_train_speech = np.array(x_train_speech)\n",
    "x_train_speech.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = label_binarize(Y,emotions_used)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_29 (Conv1D)           (None, 201, 256)          230656    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 201, 256)          0         \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 201, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 201, 128)          98432     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 201, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 201, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 201, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 201, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 201, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 201, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 201, 32)           0         \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 201, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 6432)              0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 6432)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               1646848   \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,007,780\n",
      "Trainable params: 2,007,780\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 3, padding=\"same\", input_shape=(201, 300))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"same\")`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(Convolution1D(256, 3, border_mode='same', input_shape=(201, 300)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution1D(128, 3, border_mode='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution1D(64, 3, border_mode='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution1D(32, 3, border_mode='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.5278 - acc: 0.3655 - val_loss: 1.2893 - val_acc: 0.3927\n",
      "Epoch 2/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.3808 - acc: 0.4151 - val_loss: 1.2075 - val_acc: 0.4383\n",
      "Epoch 3/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.2551 - acc: 0.4260 - val_loss: 1.1657 - val_acc: 0.4899\n",
      "Epoch 4/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.2106 - acc: 0.4491 - val_loss: 1.1853 - val_acc: 0.4514\n",
      "Epoch 5/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.1702 - acc: 0.4580 - val_loss: 1.2019 - val_acc: 0.4747\n",
      "Epoch 6/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.1756 - acc: 0.4633 - val_loss: 1.1700 - val_acc: 0.4909\n",
      "Epoch 7/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.1674 - acc: 0.4770 - val_loss: 1.1655 - val_acc: 0.5051\n",
      "Epoch 8/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.1402 - acc: 0.4754 - val_loss: 1.1572 - val_acc: 0.5020\n",
      "Epoch 9/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.1318 - acc: 0.4787 - val_loss: 1.1752 - val_acc: 0.5000\n",
      "Epoch 10/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.1114 - acc: 0.4937 - val_loss: 1.1936 - val_acc: 0.4929\n",
      "Epoch 11/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.1256 - acc: 0.4876 - val_loss: 1.1861 - val_acc: 0.4858\n",
      "Epoch 12/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.1083 - acc: 0.4944 - val_loss: 1.1881 - val_acc: 0.5010\n",
      "Epoch 13/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.0772 - acc: 0.5225 - val_loss: 1.2198 - val_acc: 0.4666\n",
      "Epoch 14/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.0347 - acc: 0.5276 - val_loss: 1.2474 - val_acc: 0.4868\n",
      "Epoch 15/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.0039 - acc: 0.5504 - val_loss: 1.2952 - val_acc: 0.4504\n",
      "Epoch 16/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.9866 - acc: 0.5765 - val_loss: 1.3644 - val_acc: 0.4676\n",
      "Epoch 17/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.0027 - acc: 0.5747 - val_loss: 1.3175 - val_acc: 0.4221\n",
      "Epoch 18/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.9473 - acc: 0.5919 - val_loss: 1.4245 - val_acc: 0.4089\n",
      "Epoch 19/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.8746 - acc: 0.6315 - val_loss: 1.4712 - val_acc: 0.4312\n",
      "Epoch 20/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.8485 - acc: 0.6553 - val_loss: 1.4359 - val_acc: 0.4453\n",
      "Epoch 21/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.8094 - acc: 0.6735 - val_loss: 1.5549 - val_acc: 0.3998\n",
      "Epoch 22/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.7509 - acc: 0.6900 - val_loss: 1.7909 - val_acc: 0.4200\n",
      "Epoch 23/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.7890 - acc: 0.6733 - val_loss: 1.6057 - val_acc: 0.4312\n",
      "Epoch 24/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.7400 - acc: 0.7011 - val_loss: 1.6456 - val_acc: 0.4302\n",
      "Epoch 25/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.7219 - acc: 0.7074 - val_loss: 1.6910 - val_acc: 0.4059\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_speech, Y, \n",
    "                 batch_size=100, nb_epoch=25, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(optimizer='Adadelta'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, return_sequences=True, input_shape=(201, 300)))\n",
    "    model.add(LSTM(256, return_sequences=False))\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 201, 256)          570368    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,229,316\n",
      "Trainable params: 1,229,316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/40\n",
      "3948/3948 [==============================] - 27s - loss: 1.3685 - acc: 0.3478 - val_loss: 1.3650 - val_acc: 0.3694\n",
      "Epoch 2/40\n",
      "3948/3948 [==============================] - 27s - loss: 1.2988 - acc: 0.3713 - val_loss: 1.2931 - val_acc: 0.4109\n",
      "Epoch 3/40\n",
      "3948/3948 [==============================] - 26s - loss: 1.2345 - acc: 0.4119 - val_loss: 1.2985 - val_acc: 0.3431\n",
      "Epoch 4/40\n",
      "3948/3948 [==============================] - 26s - loss: 1.2043 - acc: 0.4392 - val_loss: 1.2459 - val_acc: 0.4241\n",
      "Epoch 5/40\n",
      "3948/3948 [==============================] - 27s - loss: 1.1888 - acc: 0.4521 - val_loss: 1.2853 - val_acc: 0.3765\n",
      "Epoch 6/40\n",
      "3948/3948 [==============================] - 26s - loss: 1.1692 - acc: 0.4547 - val_loss: 1.2403 - val_acc: 0.4251\n",
      "Epoch 7/40\n",
      "3948/3948 [==============================] - 26s - loss: 1.1447 - acc: 0.4754 - val_loss: 1.2963 - val_acc: 0.3957\n",
      "Epoch 8/40\n",
      "3948/3948 [==============================] - 26s - loss: 1.1296 - acc: 0.4785 - val_loss: 1.2833 - val_acc: 0.4170\n",
      "Epoch 9/40\n",
      "3948/3948 [==============================] - 26s - loss: 1.1036 - acc: 0.5025 - val_loss: 1.3173 - val_acc: 0.4089\n",
      "Epoch 10/40\n",
      "3948/3948 [==============================] - 26s - loss: 1.0830 - acc: 0.5165 - val_loss: 1.3039 - val_acc: 0.3877\n",
      "Epoch 11/40\n",
      "3948/3948 [==============================] - 26s - loss: 1.0652 - acc: 0.5251 - val_loss: 1.3299 - val_acc: 0.3897\n",
      "Epoch 12/40\n",
      "3948/3948 [==============================] - 26s - loss: 1.0212 - acc: 0.5585 - val_loss: 1.3235 - val_acc: 0.4130\n",
      "Epoch 13/40\n",
      "3948/3948 [==============================] - 25s - loss: 0.9914 - acc: 0.5778 - val_loss: 1.3469 - val_acc: 0.4312\n",
      "Epoch 14/40\n",
      "3948/3948 [==============================] - 26s - loss: 0.9569 - acc: 0.5917 - val_loss: 1.4957 - val_acc: 0.3978\n",
      "Epoch 15/40\n",
      "3948/3948 [==============================] - 26s - loss: 0.9160 - acc: 0.6152 - val_loss: 1.4061 - val_acc: 0.4130\n",
      "Epoch 16/40\n",
      "3948/3948 [==============================] - 26s - loss: 0.8699 - acc: 0.6439 - val_loss: 1.6640 - val_acc: 0.3887\n",
      "Epoch 17/40\n",
      "3948/3948 [==============================] - 26s - loss: 0.8223 - acc: 0.6565 - val_loss: 1.4411 - val_acc: 0.4190\n",
      "Epoch 18/40\n",
      "3948/3948 [==============================] - 26s - loss: 0.7767 - acc: 0.6814 - val_loss: 1.5214 - val_acc: 0.3978\n",
      "Epoch 19/40\n",
      " 500/3948 [==>...........................] - ETA: 21s - loss: 0.8034 - acc: 0.6700"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-f3d31da8e3b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model.fit(x_train_speech, Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_speech, Y, \n",
    "                 batch_size=100, nb_epoch=40, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(frames, freq, options):\n",
    "    window_sec = 0.2\n",
    "    window_n = int(freq * window_sec)\n",
    "\n",
    "    st_f = stFeatureExtraction(frames, freq, window_n, window_n / 2)\n",
    "\n",
    "    if st_f.shape[1] > 2:\n",
    "        i0 = 1\n",
    "        i1 = st_f.shape[1] - 1\n",
    "        if i1 - i0 < 1:\n",
    "            i1 = i0 + 1\n",
    "        \n",
    "        deriv_st_f = np.zeros((st_f.shape[0], i1 - i0), dtype=float)\n",
    "        for i in range(i0, i1):\n",
    "            i_left = i - 1\n",
    "            i_right = i + 1\n",
    "            deriv_st_f[:st_f.shape[0], i - i0] = st_f[:, i]\n",
    "        return deriv_st_f\n",
    "    elif st_f.shape[1] == 2:\n",
    "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "        return deriv_st_f\n",
    "    else:\n",
    "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "        return deriv_st_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4936, 100, 34)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_feat = []\n",
    "\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['signal']\n",
    "    st_features = calculate_features(x_head, framerate, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "    x_train_feat.append( st_features.T )\n",
    "    counter+=1\n",
    "    if(counter%100==0):\n",
    "        print(counter)\n",
    "    \n",
    "x_train_feat = np.array(x_train_feat)\n",
    "x_train_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model_combined(optimizer='Adam'):\n",
    "    modela = Sequential()\n",
    "    modela.add(Flatten(input_shape=(100, 34)))\n",
    "    modela.add(Dense(1024))\n",
    "    modela.add(Activation('relu'))\n",
    "    modela.add(Dense(256))\n",
    "    \n",
    "    modelb = Sequential()\n",
    "    #model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "    modelb.add(Convolution1D(256, 3, border_mode='same', input_shape=(201, 300)))\n",
    "    modelb.add(Dropout(0.2))\n",
    "    modelb.add(Activation('relu'))\n",
    "    modelb.add(Convolution1D(128, 3, border_mode='same'))\n",
    "    modelb.add(Dropout(0.2))\n",
    "    modelb.add(Activation('relu'))\n",
    "    modelb.add(Convolution1D(64, 3, border_mode='same'))\n",
    "    modelb.add(Dropout(0.2))\n",
    "    modelb.add(Activation('relu'))\n",
    "    modelb.add(Convolution1D(32, 3, border_mode='same'))\n",
    "    modelb.add(Dropout(0.2))\n",
    "    modelb.add(Activation('relu'))\n",
    "    modelb.add(Flatten())\n",
    "    modelb.add(Dense(256))\n",
    "    \n",
    "    model_combined = Sequential()\n",
    "    model_combined.add(Merge([modela, modelb], mode='concat'))\n",
    "    model_combined.add(Activation('relu'))\n",
    "    \n",
    "    model_combined.add(Dense(4))\n",
    "    model_combined.add(Activation('softmax'))\n",
    "\n",
    "    model_combined.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_1 (Merge)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 5,753,828\n",
      "Trainable params: 5,753,828\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 3, padding=\"same\", input_shape=(201, 300))`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, padding=\"same\")`\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\")`\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:26: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model = linear_model_combined()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/25\n",
      "3948/3948 [==============================] - 3s - loss: 3.1072 - acc: 0.3782 - val_loss: 1.3515 - val_acc: 0.4474\n",
      "Epoch 2/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.2129 - acc: 0.4580 - val_loss: 1.2241 - val_acc: 0.4757\n",
      "Epoch 3/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.1117 - acc: 0.5182 - val_loss: 1.2740 - val_acc: 0.4443\n",
      "Epoch 4/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.0707 - acc: 0.5420 - val_loss: 1.3084 - val_acc: 0.4575\n",
      "Epoch 5/25\n",
      "3948/3948 [==============================] - 2s - loss: 1.0295 - acc: 0.5605 - val_loss: 1.3696 - val_acc: 0.4555\n",
      "Epoch 6/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.9619 - acc: 0.5864 - val_loss: 1.3387 - val_acc: 0.4980\n",
      "Epoch 7/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.9426 - acc: 0.5899 - val_loss: 1.3813 - val_acc: 0.4798\n",
      "Epoch 8/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.8998 - acc: 0.6236 - val_loss: 1.3300 - val_acc: 0.5040\n",
      "Epoch 9/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.9014 - acc: 0.6241 - val_loss: 1.3138 - val_acc: 0.4848\n",
      "Epoch 10/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.8505 - acc: 0.6401 - val_loss: 1.2368 - val_acc: 0.4787\n",
      "Epoch 11/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.8062 - acc: 0.6581 - val_loss: 1.3937 - val_acc: 0.4970\n",
      "Epoch 12/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.8017 - acc: 0.6593 - val_loss: 1.3541 - val_acc: 0.4929\n",
      "Epoch 13/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.7802 - acc: 0.6689 - val_loss: 1.2635 - val_acc: 0.5172\n",
      "Epoch 14/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.7336 - acc: 0.6945 - val_loss: 1.4928 - val_acc: 0.5020\n",
      "Epoch 15/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.7504 - acc: 0.6869 - val_loss: 1.4053 - val_acc: 0.4929\n",
      "Epoch 16/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.6962 - acc: 0.7085 - val_loss: 1.3507 - val_acc: 0.5061\n",
      "Epoch 17/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.6773 - acc: 0.7221 - val_loss: 1.6373 - val_acc: 0.4626\n",
      "Epoch 18/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.6529 - acc: 0.7338 - val_loss: 1.6139 - val_acc: 0.5020\n",
      "Epoch 19/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.6053 - acc: 0.7518 - val_loss: 1.4164 - val_acc: 0.5182\n",
      "Epoch 20/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.5715 - acc: 0.7672 - val_loss: 1.8501 - val_acc: 0.4686\n",
      "Epoch 21/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.5660 - acc: 0.7667 - val_loss: 1.7232 - val_acc: 0.4787\n",
      "Epoch 22/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.5137 - acc: 0.7953 - val_loss: 1.6761 - val_acc: 0.4899\n",
      "Epoch 23/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.4879 - acc: 0.8080 - val_loss: 1.7131 - val_acc: 0.4828\n",
      "Epoch 24/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.4478 - acc: 0.8232 - val_loss: 1.9362 - val_acc: 0.4879\n",
      "Epoch 25/25\n",
      "3948/3948 [==============================] - 2s - loss: 0.4336 - acc: 0.8313 - val_loss: 2.3973 - val_acc: 0.4828\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit([x_train_feat, x_train_speech], Y, \n",
    "                 batch_size=100, nb_epoch=25, verbose=1, shuffle = True, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
