{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import wave\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import LSTM, Input, Flatten, Merge, Embedding, Convolution1D,Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "from features import *\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n",
    "data_path = code_path + \"/../data/sessions/\"\n",
    "sessions = ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']\n",
    "framerate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(data_path + '/../'+'data_collected.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for ses_mod in data2:\n",
    "    text.append(ses_mod['transcription'])\n",
    "    \n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "token_tr_X = tokenizer.texts_to_sequences(text)\n",
    "x_train_text = []\n",
    "\n",
    "x_train_text = sequence.pad_sequences(token_tr_X, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2736 unique tokens\n",
      "/home/samarth/emotion_recognition-master/code/../data/sessions/../glove.42B.300d.txt\n",
      "G Word embeddings: 1917494\n",
      "G Null word embeddings: 90\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "file_loc = data_path + '../glove.42B.300d.txt'\n",
    "\n",
    "print (file_loc)\n",
    "\n",
    "gembeddings_index = {}\n",
    "with codecs.open(file_loc, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        gembedding = np.asarray(values[1:], dtype='float32')\n",
    "        gembeddings_index[word] = gembedding\n",
    "#\n",
    "f.close()\n",
    "print('G Word embeddings:', len(gembeddings_index))\n",
    "\n",
    "nb_words = len(word_index) +1\n",
    "g_word_embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    gembedding_vector = gembeddings_index.get(word)\n",
    "    if gembedding_vector is not None:\n",
    "        g_word_embedding_matrix[i] = gembedding_vector\n",
    "        \n",
    "print('G Null word embeddings: %d' % np.sum(np.sum(g_word_embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(frames, freq, options):\n",
    "    window_sec = 0.2\n",
    "    window_n = int(freq * window_sec)\n",
    "\n",
    "    st_f = stFeatureExtraction(frames, freq, window_n, window_n / 2)\n",
    "\n",
    "    if st_f.shape[1] > 2:\n",
    "        i0 = 1\n",
    "        i1 = st_f.shape[1] - 1\n",
    "        if i1 - i0 < 1:\n",
    "            i1 = i0 + 1\n",
    "        \n",
    "        deriv_st_f = np.zeros((st_f.shape[0], i1 - i0), dtype=float)\n",
    "        for i in range(i0, i1):\n",
    "            i_left = i - 1\n",
    "            i_right = i + 1\n",
    "            deriv_st_f[:st_f.shape[0], i - i0] = st_f[:, i]\n",
    "        return deriv_st_f\n",
    "    elif st_f.shape[1] == 2:\n",
    "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "        return deriv_st_f\n",
    "    else:\n",
    "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "        return deriv_st_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4936, 100, 34)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_speech = []\n",
    "\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['signal']\n",
    "    st_features = calculate_features(x_head, framerate, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "    x_train_speech.append( st_features.T )\n",
    "    counter+=1\n",
    "    if(counter%100==0):\n",
    "        print(counter)\n",
    "    \n",
    "x_train_speech = np.array(x_train_speech)\n",
    "x_train_speech.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 200, 189, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mocap = []\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['mocap_head']\n",
    "    if(x_head.shape != (200,18)):\n",
    "        x_head = np.zeros((200,18))   \n",
    "    x_head[np.isnan(x_head)]=0\n",
    "    x_hand = ses_mod['mocap_hand']\n",
    "    if(x_hand.shape != (200,6)):\n",
    "        x_hand = np.zeros((200,6))   \n",
    "    x_hand[np.isnan(x_hand)]=0\n",
    "    x_rot = ses_mod['mocap_rot']\n",
    "    if(x_rot.shape != (200,165)):\n",
    "        x_rot = np.zeros((200,165))   \n",
    "    x_rot[np.isnan(x_rot)]=0\n",
    "    x_mocap = np.concatenate((x_head, x_hand), axis=1)\n",
    "    x_mocap = np.concatenate((x_mocap, x_rot), axis=1)\n",
    "    x_train_mocap.append( x_mocap )\n",
    "    \n",
    "x_train_mocap = np.array(x_train_mocap)\n",
    "x_train_mocap = x_train_mocap.reshape(-1,200,189,1)\n",
    "x_train_mocap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = label_binarize(Y,emotions_used)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, padding=\"same\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:36: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 3400)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1024)              3482624   \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               131328    \n",
      "=================================================================\n",
      "Total params: 4,138,752\n",
      "Trainable params: 4,138,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 500, 256)          230656    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 500, 128)          98432     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 500, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 500, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               4096256   \n",
      "=================================================================\n",
      "Total params: 5,277,260\n",
      "Trainable params: 5,277,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_5 (Merge)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 9,418,064\n",
      "Trainable params: 9,418,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "model_text.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(128, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(64, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(32, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Flatten())\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(100, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(512))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech], mode='concat'))\n",
    "\n",
    "#model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/125\n",
      "3948/3948 [==============================] - 6s - loss: 1.5830 - acc: 0.3387 - val_loss: 1.2644 - val_acc: 0.4312\n",
      "Epoch 2/125\n",
      "3948/3948 [==============================] - 5s - loss: 1.2069 - acc: 0.4435 - val_loss: 1.1804 - val_acc: 0.4383\n",
      "Epoch 3/125\n",
      "3948/3948 [==============================] - 5s - loss: 1.1578 - acc: 0.4648 - val_loss: 1.2301 - val_acc: 0.4362\n",
      "Epoch 4/125\n",
      "3948/3948 [==============================] - 5s - loss: 1.1096 - acc: 0.4851 - val_loss: 1.2233 - val_acc: 0.4838\n",
      "Epoch 5/125\n",
      "3948/3948 [==============================] - 5s - loss: 1.0949 - acc: 0.4924 - val_loss: 1.1475 - val_acc: 0.4949\n",
      "Epoch 6/125\n",
      "3948/3948 [==============================] - 5s - loss: 1.0735 - acc: 0.5122 - val_loss: 1.2846 - val_acc: 0.3978\n",
      "Epoch 7/125\n",
      "3948/3948 [==============================] - 5s - loss: 1.0459 - acc: 0.5187 - val_loss: 1.2391 - val_acc: 0.4555\n",
      "Epoch 8/125\n",
      "3948/3948 [==============================] - 5s - loss: 1.0278 - acc: 0.5388 - val_loss: 1.1215 - val_acc: 0.4929\n",
      "Epoch 9/125\n",
      "3948/3948 [==============================] - 5s - loss: 1.0020 - acc: 0.5504 - val_loss: 1.1377 - val_acc: 0.5121\n",
      "Epoch 10/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.9812 - acc: 0.5691 - val_loss: 1.2989 - val_acc: 0.4332\n",
      "Epoch 11/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.9822 - acc: 0.5636 - val_loss: 1.1484 - val_acc: 0.5000\n",
      "Epoch 12/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.9593 - acc: 0.5823 - val_loss: 1.2729 - val_acc: 0.4696\n",
      "Epoch 13/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.9439 - acc: 0.5922 - val_loss: 1.2443 - val_acc: 0.4717\n",
      "Epoch 14/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.9194 - acc: 0.6018 - val_loss: 1.2590 - val_acc: 0.4706\n",
      "Epoch 15/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.9047 - acc: 0.6089 - val_loss: 1.1961 - val_acc: 0.5121\n",
      "Epoch 16/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.8863 - acc: 0.6213 - val_loss: 1.1963 - val_acc: 0.4980\n",
      "Epoch 17/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.8630 - acc: 0.6282 - val_loss: 1.2933 - val_acc: 0.4808\n",
      "Epoch 18/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.8540 - acc: 0.6231 - val_loss: 1.1958 - val_acc: 0.5172\n",
      "Epoch 19/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.8641 - acc: 0.6322 - val_loss: 1.1857 - val_acc: 0.5294\n",
      "Epoch 20/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.8118 - acc: 0.6499 - val_loss: 1.3134 - val_acc: 0.4879\n",
      "Epoch 21/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.8058 - acc: 0.6479 - val_loss: 1.3125 - val_acc: 0.4960\n",
      "Epoch 22/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.8152 - acc: 0.6497 - val_loss: 1.2639 - val_acc: 0.5142\n",
      "Epoch 23/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.7812 - acc: 0.6570 - val_loss: 1.3484 - val_acc: 0.5132\n",
      "Epoch 24/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.7558 - acc: 0.6796 - val_loss: 1.4315 - val_acc: 0.5263\n",
      "Epoch 25/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.7770 - acc: 0.6636 - val_loss: 1.4350 - val_acc: 0.4879\n",
      "Epoch 26/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.7453 - acc: 0.6758 - val_loss: 1.5222 - val_acc: 0.4757\n",
      "Epoch 27/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.7352 - acc: 0.6786 - val_loss: 1.3541 - val_acc: 0.5152\n",
      "Epoch 28/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.7264 - acc: 0.6814 - val_loss: 1.4468 - val_acc: 0.4970\n",
      "Epoch 29/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.7067 - acc: 0.6986 - val_loss: 1.5099 - val_acc: 0.5010\n",
      "Epoch 30/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.6850 - acc: 0.7100 - val_loss: 1.5679 - val_acc: 0.4980\n",
      "Epoch 31/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.6723 - acc: 0.7183 - val_loss: 1.4180 - val_acc: 0.4838\n",
      "Epoch 32/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.6611 - acc: 0.7161 - val_loss: 1.4894 - val_acc: 0.4899\n",
      "Epoch 33/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.6550 - acc: 0.7123 - val_loss: 1.5515 - val_acc: 0.4848\n",
      "Epoch 34/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.6523 - acc: 0.7305 - val_loss: 1.6169 - val_acc: 0.5040\n",
      "Epoch 35/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.6372 - acc: 0.7356 - val_loss: 1.4475 - val_acc: 0.4929\n",
      "Epoch 36/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.6228 - acc: 0.7427 - val_loss: 1.8717 - val_acc: 0.4636\n",
      "Epoch 37/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.6001 - acc: 0.7454 - val_loss: 1.5258 - val_acc: 0.5101\n",
      "Epoch 38/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.6190 - acc: 0.7351 - val_loss: 1.5823 - val_acc: 0.4808\n",
      "Epoch 39/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.5866 - acc: 0.7518 - val_loss: 1.7033 - val_acc: 0.4798\n",
      "Epoch 40/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.5528 - acc: 0.7670 - val_loss: 1.6979 - val_acc: 0.4798\n",
      "Epoch 41/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.5810 - acc: 0.7589 - val_loss: 1.6124 - val_acc: 0.4939\n",
      "Epoch 42/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.5567 - acc: 0.7708 - val_loss: 1.6892 - val_acc: 0.5061\n",
      "Epoch 43/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.5730 - acc: 0.7614 - val_loss: 1.7635 - val_acc: 0.4848\n",
      "Epoch 44/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.5441 - acc: 0.7756 - val_loss: 1.9528 - val_acc: 0.4534\n",
      "Epoch 45/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.5287 - acc: 0.7806 - val_loss: 1.6250 - val_acc: 0.4899\n",
      "Epoch 46/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4986 - acc: 0.7966 - val_loss: 1.9339 - val_acc: 0.4848\n",
      "Epoch 47/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4785 - acc: 0.7958 - val_loss: 1.9307 - val_acc: 0.4889\n",
      "Epoch 48/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4660 - acc: 0.8085 - val_loss: 1.7983 - val_acc: 0.5081\n",
      "Epoch 49/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4955 - acc: 0.7915 - val_loss: 1.7761 - val_acc: 0.4960\n",
      "Epoch 50/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4624 - acc: 0.8057 - val_loss: 1.9682 - val_acc: 0.4818\n",
      "Epoch 51/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4863 - acc: 0.7948 - val_loss: 1.9153 - val_acc: 0.4828\n",
      "Epoch 52/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4432 - acc: 0.8143 - val_loss: 2.2694 - val_acc: 0.4838\n",
      "Epoch 53/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4597 - acc: 0.8100 - val_loss: 1.8942 - val_acc: 0.4777\n",
      "Epoch 54/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4374 - acc: 0.8209 - val_loss: 2.2288 - val_acc: 0.4879\n",
      "Epoch 55/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4551 - acc: 0.8110 - val_loss: 1.8974 - val_acc: 0.4970\n",
      "Epoch 56/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4320 - acc: 0.8204 - val_loss: 2.3204 - val_acc: 0.4858\n",
      "Epoch 57/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4317 - acc: 0.8189 - val_loss: 2.3176 - val_acc: 0.4767\n",
      "Epoch 58/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4167 - acc: 0.8235 - val_loss: 2.1829 - val_acc: 0.4919\n",
      "Epoch 59/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4214 - acc: 0.8174 - val_loss: 2.1680 - val_acc: 0.4919\n",
      "Epoch 60/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4134 - acc: 0.8278 - val_loss: 2.2880 - val_acc: 0.4879\n",
      "Epoch 61/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4092 - acc: 0.8316 - val_loss: 2.3285 - val_acc: 0.4717\n",
      "Epoch 62/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4162 - acc: 0.8202 - val_loss: 2.1556 - val_acc: 0.4879\n",
      "Epoch 63/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.4333 - acc: 0.8202 - val_loss: 2.0631 - val_acc: 0.4899\n",
      "Epoch 64/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3703 - acc: 0.8473 - val_loss: 2.2425 - val_acc: 0.4960\n",
      "Epoch 65/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3948/3948 [==============================] - 5s - loss: 0.3640 - acc: 0.8508 - val_loss: 2.6504 - val_acc: 0.4787\n",
      "Epoch 66/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3516 - acc: 0.8523 - val_loss: 2.4815 - val_acc: 0.4929\n",
      "Epoch 67/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3268 - acc: 0.8647 - val_loss: 2.3972 - val_acc: 0.4990\n",
      "Epoch 68/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3705 - acc: 0.8397 - val_loss: 2.5469 - val_acc: 0.4787\n",
      "Epoch 69/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3618 - acc: 0.8475 - val_loss: 2.6451 - val_acc: 0.4393\n",
      "Epoch 70/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3624 - acc: 0.8498 - val_loss: 2.3722 - val_acc: 0.4818\n",
      "Epoch 71/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3609 - acc: 0.8594 - val_loss: 2.3271 - val_acc: 0.4990\n",
      "Epoch 72/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3736 - acc: 0.8452 - val_loss: 2.1676 - val_acc: 0.5030\n",
      "Epoch 73/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3241 - acc: 0.8716 - val_loss: 2.7074 - val_acc: 0.4737\n",
      "Epoch 74/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3465 - acc: 0.8617 - val_loss: 2.5613 - val_acc: 0.5040\n",
      "Epoch 75/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3338 - acc: 0.8668 - val_loss: 2.4086 - val_acc: 0.4899\n",
      "Epoch 76/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3471 - acc: 0.8559 - val_loss: 2.6241 - val_acc: 0.4868\n",
      "Epoch 77/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3237 - acc: 0.8640 - val_loss: 2.5896 - val_acc: 0.4737\n",
      "Epoch 78/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3652 - acc: 0.8478 - val_loss: 2.5720 - val_acc: 0.4899\n",
      "Epoch 79/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3046 - acc: 0.8728 - val_loss: 2.6633 - val_acc: 0.4960\n",
      "Epoch 80/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3323 - acc: 0.8632 - val_loss: 2.6937 - val_acc: 0.4828\n",
      "Epoch 81/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3392 - acc: 0.8630 - val_loss: 2.6406 - val_acc: 0.4767\n",
      "Epoch 82/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3269 - acc: 0.8721 - val_loss: 2.7878 - val_acc: 0.4970\n",
      "Epoch 83/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3034 - acc: 0.8706 - val_loss: 2.6349 - val_acc: 0.5061\n",
      "Epoch 84/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3552 - acc: 0.8579 - val_loss: 2.9131 - val_acc: 0.4757\n",
      "Epoch 85/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3612 - acc: 0.8417 - val_loss: 2.7329 - val_acc: 0.5091\n",
      "Epoch 86/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3340 - acc: 0.8609 - val_loss: 3.2023 - val_acc: 0.4767\n",
      "Epoch 87/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3067 - acc: 0.8754 - val_loss: 2.5880 - val_acc: 0.4919\n",
      "Epoch 88/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3150 - acc: 0.8741 - val_loss: 2.7231 - val_acc: 0.4808\n",
      "Epoch 89/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3164 - acc: 0.8728 - val_loss: 3.0418 - val_acc: 0.4909\n",
      "Epoch 90/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3119 - acc: 0.8680 - val_loss: 2.7548 - val_acc: 0.4787\n",
      "Epoch 91/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3201 - acc: 0.8635 - val_loss: 2.8097 - val_acc: 0.5030\n",
      "Epoch 92/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.2838 - acc: 0.8749 - val_loss: 2.9492 - val_acc: 0.4777\n",
      "Epoch 93/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.2948 - acc: 0.8766 - val_loss: 2.8526 - val_acc: 0.4747\n",
      "Epoch 94/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3185 - acc: 0.8663 - val_loss: 2.5746 - val_acc: 0.4808\n",
      "Epoch 95/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3083 - acc: 0.8670 - val_loss: 2.9777 - val_acc: 0.4909\n",
      "Epoch 96/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3172 - acc: 0.8620 - val_loss: 2.9921 - val_acc: 0.4949\n",
      "Epoch 97/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.3162 - acc: 0.8637 - val_loss: 2.8821 - val_acc: 0.4646\n",
      "Epoch 98/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.2781 - acc: 0.8848 - val_loss: 3.3916 - val_acc: 0.4666\n",
      "Epoch 99/125\n",
      "3948/3948 [==============================] - 5s - loss: 0.2950 - acc: 0.8711 - val_loss: 3.0803 - val_acc: 0.4605\n",
      "Epoch 100/125\n",
      "2048/3948 [==============>...............] - ETA: 2s - loss: 0.2902 - acc: 0.882"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7c7437712dfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model_combined.fit([x_train_text,x_train_speech], Y, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_split=0.2)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Last batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, force)\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0minfo\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m' - %s:'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                     \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                         \u001b[0minfo\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m' %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train_speech], Y, \n",
    "                 batch_size=64, nb_epoch=125, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_21 (Flatten)         (None, 3400)              0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1024)              3482624   \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 256)               131328    \n",
      "=================================================================\n",
      "Total params: 4,138,752\n",
      "Trainable params: 4,138,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 500, 128)          350208    \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1024)              65537024  \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               131328    \n",
      "=================================================================\n",
      "Total params: 66,543,360\n",
      "Trainable params: 66,543,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_10 (Merge)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 70,814,468\n",
      "Trainable params: 70,814,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:28: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(2736,\n",
    "                    128,input_length=500))\n",
    "model_text.add(Flatten())\n",
    "model_text.add(Dense(1024))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Dense(512))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(100, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(512))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech], mode='concat'))\n",
    "\n",
    "model_combined.add(Activation('relu'))\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      "3948/3948 [==============================] - 7s - loss: 2.3053 - acc: 0.3214 - val_loss: 1.3071 - val_acc: 0.4322\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 6s - loss: 1.1983 - acc: 0.4415 - val_loss: 1.2201 - val_acc: 0.4858\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 6s - loss: 1.1503 - acc: 0.4549 - val_loss: 1.1888 - val_acc: 0.4777\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.9828 - acc: 0.5595 - val_loss: 1.0691 - val_acc: 0.6063\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.5954 - acc: 0.7617 - val_loss: 0.9443 - val_acc: 0.6518\n",
      "Epoch 6/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.3732 - acc: 0.8609 - val_loss: 1.1165 - val_acc: 0.6387\n",
      "Epoch 7/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.2703 - acc: 0.9017 - val_loss: 1.3433 - val_acc: 0.6488\n",
      "Epoch 8/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.2165 - acc: 0.9243 - val_loss: 1.3664 - val_acc: 0.6215\n",
      "Epoch 9/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.1882 - acc: 0.9321 - val_loss: 1.6481 - val_acc: 0.6407\n",
      "Epoch 10/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.1910 - acc: 0.9298 - val_loss: 1.4425 - val_acc: 0.6518\n",
      "Epoch 11/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.2858 - acc: 0.8934 - val_loss: 1.2331 - val_acc: 0.6346\n",
      "Epoch 12/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.1808 - acc: 0.9349 - val_loss: 1.6158 - val_acc: 0.6498\n",
      "Epoch 13/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.1234 - acc: 0.9498 - val_loss: 1.9155 - val_acc: 0.6538\n",
      "Epoch 14/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.1515 - acc: 0.9397 - val_loss: 1.7322 - val_acc: 0.6296\n",
      "Epoch 15/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.1134 - acc: 0.9544 - val_loss: 1.9050 - val_acc: 0.6346\n",
      "Epoch 16/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.1027 - acc: 0.9630 - val_loss: 1.8604 - val_acc: 0.6296\n",
      "Epoch 17/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0994 - acc: 0.9625 - val_loss: 2.0298 - val_acc: 0.6478\n",
      "Epoch 18/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.1045 - acc: 0.9582 - val_loss: 1.8735 - val_acc: 0.6427\n",
      "Epoch 19/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0858 - acc: 0.9676 - val_loss: 2.2017 - val_acc: 0.6366\n",
      "Epoch 20/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0862 - acc: 0.9648 - val_loss: 2.0849 - val_acc: 0.6397\n",
      "Epoch 21/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0725 - acc: 0.9709 - val_loss: 2.4163 - val_acc: 0.6407\n",
      "Epoch 22/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0731 - acc: 0.9709 - val_loss: 2.1726 - val_acc: 0.6184\n",
      "Epoch 23/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0687 - acc: 0.9732 - val_loss: 2.4108 - val_acc: 0.6255\n",
      "Epoch 24/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0791 - acc: 0.9714 - val_loss: 2.8421 - val_acc: 0.5820\n",
      "Epoch 25/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0978 - acc: 0.9650 - val_loss: 2.2233 - val_acc: 0.6356\n",
      "Epoch 26/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0734 - acc: 0.9734 - val_loss: 2.4309 - val_acc: 0.6346\n",
      "Epoch 27/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0759 - acc: 0.9729 - val_loss: 2.3905 - val_acc: 0.6306\n",
      "Epoch 28/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0878 - acc: 0.9648 - val_loss: 2.4022 - val_acc: 0.6366\n",
      "Epoch 29/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0711 - acc: 0.9747 - val_loss: 2.2783 - val_acc: 0.6083\n",
      "Epoch 30/30\n",
      "3948/3948 [==============================] - 6s - loss: 0.0594 - acc: 0.9782 - val_loss: 2.5326 - val_acc: 0.6346\n"
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train_speech], Y, \n",
    "                 batch_size=64, nb_epoch=30, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_23 (Flatten)         (None, 3400)              0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1024)              3482624   \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 256)               262400    \n",
      "=================================================================\n",
      "Total params: 3,745,024\n",
      "Trainable params: 3,745,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 500, 128)          350208    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 500, 256)          394240    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 1,335,552\n",
      "Trainable params: 1,335,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_12 (Merge)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 5,212,932\n",
      "Trainable params: 5,212,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:20: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(2736,\n",
    "                    128,input_length=500))\n",
    "\n",
    "model_text.add(LSTM(256, return_sequences=True, input_shape=(100, 34)))\n",
    "model_text.add(LSTM(256, return_sequences=False))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(100, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech], mode='concat'))\n",
    "\n",
    "model_combined.add(Activation('relu'))\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/10\n",
      "3948/3948 [==============================] - 96s - loss: 1.5177 - acc: 0.3883 - val_loss: 1.1521 - val_acc: 0.5030\n",
      "Epoch 2/10\n",
      "3948/3948 [==============================] - 95s - loss: 1.0155 - acc: 0.5585 - val_loss: 1.0288 - val_acc: 0.5911\n",
      "Epoch 3/10\n",
      "3948/3948 [==============================] - 95s - loss: 0.8338 - acc: 0.6537 - val_loss: 1.1359 - val_acc: 0.5911\n",
      "Epoch 4/10\n",
      "3948/3948 [==============================] - 96s - loss: 0.6285 - acc: 0.7457 - val_loss: 1.0116 - val_acc: 0.6569\n",
      "Epoch 5/10\n",
      "3948/3948 [==============================] - 95s - loss: 0.5209 - acc: 0.8045 - val_loss: 0.9996 - val_acc: 0.6538\n",
      "Epoch 6/10\n",
      "3948/3948 [==============================] - 96s - loss: 0.4503 - acc: 0.8247 - val_loss: 1.0920 - val_acc: 0.6528\n",
      "Epoch 7/10\n",
      "3948/3948 [==============================] - 95s - loss: 0.3838 - acc: 0.8531 - val_loss: 1.0566 - val_acc: 0.6630\n",
      "Epoch 8/10\n",
      "3948/3948 [==============================] - 95s - loss: 0.3398 - acc: 0.8754 - val_loss: 1.1103 - val_acc: 0.6741\n",
      "Epoch 9/10\n",
      "3948/3948 [==============================] - 95s - loss: 0.3241 - acc: 0.8759 - val_loss: 1.3626 - val_acc: 0.6417\n",
      "Epoch 10/10\n",
      "3948/3948 [==============================] - 95s - loss: 0.2826 - acc: 0.8934 - val_loss: 1.3764 - val_acc: 0.6447\n"
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train_speech], Y, \n",
    "                 batch_size=64, nb_epoch=10, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_24 (Flatten)         (None, 3400)              0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1024)              3482624   \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 256)               262400    \n",
      "=================================================================\n",
      "Total params: 3,745,024\n",
      "Trainable params: 3,745,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 500, 256)          570368    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 1,982,572\n",
      "Trainable params: 1,982,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_13 (Merge)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 5,859,952\n",
      "Trainable params: 5,859,952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:23: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "\n",
    "model_text.add(LSTM(256, return_sequences=True))\n",
    "model_text.add(LSTM(256, return_sequences=False))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(100, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech], mode='concat'))\n",
    "\n",
    "model_combined.add(Activation('relu'))\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/10\n",
      "3948/3948 [==============================] - 99s - loss: 1.4061 - acc: 0.3982 - val_loss: 1.1408 - val_acc: 0.5192\n",
      "Epoch 2/10\n",
      "3948/3948 [==============================] - 98s - loss: 0.9457 - acc: 0.6013 - val_loss: 1.0741 - val_acc: 0.5648\n",
      "Epoch 3/10\n",
      "3948/3948 [==============================] - 96s - loss: 0.7025 - acc: 0.7171 - val_loss: 0.8983 - val_acc: 0.6559\n",
      "Epoch 4/10\n",
      "3948/3948 [==============================] - 97s - loss: 0.5498 - acc: 0.7781 - val_loss: 0.8956 - val_acc: 0.6913\n",
      "Epoch 5/10\n",
      "3948/3948 [==============================] - 97s - loss: 0.4412 - acc: 0.8311 - val_loss: 0.9891 - val_acc: 0.6761\n",
      "Epoch 6/10\n",
      "3948/3948 [==============================] - 97s - loss: 0.3530 - acc: 0.8642 - val_loss: 0.9266 - val_acc: 0.6751\n",
      "Epoch 7/10\n",
      "3948/3948 [==============================] - 97s - loss: 0.3004 - acc: 0.8891 - val_loss: 1.0780 - val_acc: 0.6832\n",
      "Epoch 8/10\n",
      "3948/3948 [==============================] - 97s - loss: 0.2696 - acc: 0.8969 - val_loss: 1.2045 - val_acc: 0.6974\n",
      "Epoch 9/10\n",
      "3948/3948 [==============================] - 97s - loss: 0.2246 - acc: 0.9126 - val_loss: 1.1845 - val_acc: 0.6791\n",
      "Epoch 10/10\n",
      "3948/3948 [==============================] - 96s - loss: 0.1954 - acc: 0.9217 - val_loss: 1.2890 - val_acc: 0.6700\n"
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train_speech], Y, \n",
    "                 batch_size=64, nb_epoch=10, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_29 (Flatten)         (None, 3400)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 1024)              3482624   \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 256)               262400    \n",
      "=================================================================\n",
      "Total params: 3,745,024\n",
      "Trainable params: 3,745,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 500, 256)          570368    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 1,982,572\n",
      "Trainable params: 1,982,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 100, 95, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 50, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 25, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 13, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 256)               1376512   \n",
      "=================================================================\n",
      "Total params: 1,653,696\n",
      "Trainable params: 1,653,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_16 (Merge)             (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 7,579,184\n",
      "Trainable params: 7,579,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, strides=(2, 2), padding=\"same\", input_shape=(200, 189,...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "\n",
    "model_text.add(LSTM(256, return_sequences=True))\n",
    "model_text.add(LSTM(256, return_sequences=False))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(100, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "model_mocap = Sequential()\n",
    "model_mocap.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 189, 1)))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Flatten())\n",
    "model_mocap.add(Dense(256))\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech, model_mocap], mode='concat'))\n",
    "\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_mocap.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/20\n",
      "3948/3948 [==============================] - 104s - loss: 2.1268 - acc: 0.3734 - val_loss: 1.1610 - val_acc: 0.4949\n",
      "Epoch 2/20\n",
      "3948/3948 [==============================] - 100s - loss: 0.9963 - acc: 0.5732 - val_loss: 0.9263 - val_acc: 0.6326\n",
      "Epoch 3/20\n",
      "3948/3948 [==============================] - 100s - loss: 0.7343 - acc: 0.7085 - val_loss: 0.8728 - val_acc: 0.6650\n",
      "Epoch 4/20\n",
      "3948/3948 [==============================] - 101s - loss: 0.5629 - acc: 0.7804 - val_loss: 0.8316 - val_acc: 0.6781\n",
      "Epoch 5/20\n",
      "3948/3948 [==============================] - 100s - loss: 0.4776 - acc: 0.8179 - val_loss: 0.9013 - val_acc: 0.6802\n",
      "Epoch 6/20\n",
      "3948/3948 [==============================] - 101s - loss: 0.3749 - acc: 0.8597 - val_loss: 0.9670 - val_acc: 0.6832\n",
      "Epoch 7/20\n",
      "3948/3948 [==============================] - 100s - loss: 0.3061 - acc: 0.8827 - val_loss: 0.9723 - val_acc: 0.6852\n",
      "Epoch 8/20\n",
      "3948/3948 [==============================] - 100s - loss: 0.2569 - acc: 0.9017 - val_loss: 1.3175 - val_acc: 0.6528\n",
      "Epoch 9/20\n",
      "3948/3948 [==============================] - 101s - loss: 0.2383 - acc: 0.9078 - val_loss: 1.1855 - val_acc: 0.6842\n",
      "Epoch 10/20\n",
      "3948/3948 [==============================] - 100s - loss: 0.1892 - acc: 0.9283 - val_loss: 1.2382 - val_acc: 0.6903\n",
      "Epoch 11/20\n",
      "3948/3948 [==============================] - 100s - loss: 0.1704 - acc: 0.9362 - val_loss: 1.2678 - val_acc: 0.6903\n",
      "Epoch 12/20\n",
      "3948/3948 [==============================] - 100s - loss: 0.1486 - acc: 0.9435 - val_loss: 1.5073 - val_acc: 0.6822\n",
      "Epoch 13/20\n",
      "3948/3948 [==============================] - 98s - loss: 0.1674 - acc: 0.9344 - val_loss: 1.4478 - val_acc: 0.6660\n",
      "Epoch 14/20\n",
      "3948/3948 [==============================] - 99s - loss: 0.1421 - acc: 0.9458 - val_loss: 1.5075 - val_acc: 0.6872\n",
      "Epoch 15/20\n",
      "3948/3948 [==============================] - 101s - loss: 0.1388 - acc: 0.9453 - val_loss: 1.8462 - val_acc: 0.6700\n",
      "Epoch 16/20\n",
      "3948/3948 [==============================] - 99s - loss: 0.1204 - acc: 0.9542 - val_loss: 1.7269 - val_acc: 0.6731\n",
      "Epoch 17/20\n",
      "3948/3948 [==============================] - 101s - loss: 0.1217 - acc: 0.9564 - val_loss: 1.8225 - val_acc: 0.6640\n",
      "Epoch 18/20\n",
      "3948/3948 [==============================] - 100s - loss: 0.1284 - acc: 0.9504 - val_loss: 1.4414 - val_acc: 0.6994\n",
      "Epoch 19/20\n",
      "3948/3948 [==============================] - 100s - loss: 0.0851 - acc: 0.9683 - val_loss: 1.7777 - val_acc: 0.6802\n",
      "Epoch 20/20\n",
      "3948/3948 [==============================] - 100s - loss: 0.0788 - acc: 0.9714 - val_loss: 1.8701 - val_acc: 0.6761\n"
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train_speech,x_train_mocap], Y, \n",
    "                 batch_size=64, nb_epoch=20, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(256, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 3, padding=\"same\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 3, padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, strides=(2, 2), padding=\"same\", input_shape=(200, 189,...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_35 (Flatten)         (None, 3400)              0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 1024)              3482624   \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 256)               262400    \n",
      "=================================================================\n",
      "Total params: 3,745,024\n",
      "Trainable params: 3,745,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 500, 256)          230656    \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 500, 128)          98432     \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 500, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 500, 32)           6176      \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 256)               4096256   \n",
      "=================================================================\n",
      "Total params: 5,277,260\n",
      "Trainable params: 5,277,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 100, 95, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 50, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 25, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 13, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 256)               1376512   \n",
      "=================================================================\n",
      "Total params: 1,653,696\n",
      "Trainable params: 1,653,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_18 (Merge)             (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 10,873,872\n",
      "Trainable params: 10,873,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:52: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "model_text.add(Convolution1D(256, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(128, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(64, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Convolution1D(32, 3, border_mode='same'))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Activation('relu'))\n",
    "model_text.add(Flatten())\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(100, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "model_mocap = Sequential()\n",
    "model_mocap.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 189, 1)))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Flatten())\n",
    "model_mocap.add(Dense(256))\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech, model_mocap], mode='concat'))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_mocap.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/60\n",
      "3948/3948 [==============================] - 14s - loss: 2.1924 - acc: 0.3336 - val_loss: 1.2536 - val_acc: 0.4332\n",
      "Epoch 2/60\n",
      "3948/3948 [==============================] - 13s - loss: 1.2030 - acc: 0.4397 - val_loss: 1.1904 - val_acc: 0.4626\n",
      "Epoch 3/60\n",
      "3948/3948 [==============================] - 13s - loss: 1.1540 - acc: 0.4514 - val_loss: 1.1939 - val_acc: 0.4656\n",
      "Epoch 4/60\n",
      "3948/3948 [==============================] - 13s - loss: 1.1148 - acc: 0.4792 - val_loss: 1.2296 - val_acc: 0.4555\n",
      "Epoch 5/60\n",
      "3948/3948 [==============================] - 13s - loss: 1.0330 - acc: 0.5433 - val_loss: 1.0895 - val_acc: 0.5536A: 3s - loss: \n",
      "Epoch 6/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.9839 - acc: 0.5704 - val_loss: 1.1032 - val_acc: 0.5617\n",
      "Epoch 7/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.9574 - acc: 0.5912 - val_loss: 1.0948 - val_acc: 0.5283\n",
      "Epoch 8/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.9194 - acc: 0.5950 - val_loss: 1.1937 - val_acc: 0.5000\n",
      "Epoch 9/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.9214 - acc: 0.5985 - val_loss: 1.0704 - val_acc: 0.5395\n",
      "Epoch 10/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.8784 - acc: 0.6112 - val_loss: 1.0415 - val_acc: 0.5891\n",
      "Epoch 11/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.8391 - acc: 0.6315 - val_loss: 1.0273 - val_acc: 0.5739\n",
      "Epoch 12/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.8289 - acc: 0.6421 - val_loss: 1.0449 - val_acc: 0.5516\n",
      "Epoch 13/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.8410 - acc: 0.6408 - val_loss: 1.0385 - val_acc: 0.5729.646 - ET\n",
      "Epoch 14/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.7846 - acc: 0.6684 - val_loss: 1.0043 - val_acc: 0.5921\n",
      "Epoch 15/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.7580 - acc: 0.6765 - val_loss: 1.1470 - val_acc: 0.5455\n",
      "Epoch 16/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.7507 - acc: 0.6821 - val_loss: 1.0584 - val_acc: 0.5557\n",
      "Epoch 17/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.7213 - acc: 0.6910 - val_loss: 1.2362 - val_acc: 0.5435\n",
      "Epoch 18/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.7179 - acc: 0.6907 - val_loss: 1.1489 - val_acc: 0.5496\n",
      "Epoch 19/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.6825 - acc: 0.7156 - val_loss: 1.1656 - val_acc: 0.5678\n",
      "Epoch 20/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.6775 - acc: 0.7168 - val_loss: 1.1503 - val_acc: 0.5607\n",
      "Epoch 21/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.6424 - acc: 0.7254 - val_loss: 1.1553 - val_acc: 0.5597\n",
      "Epoch 22/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.6504 - acc: 0.7300 - val_loss: 1.1209 - val_acc: 0.5810.7\n",
      "Epoch 23/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.6210 - acc: 0.7394 - val_loss: 1.1930 - val_acc: 0.5506\n",
      "Epoch 24/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.6059 - acc: 0.7535 - val_loss: 1.2148 - val_acc: 0.5638\n",
      "Epoch 25/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.5700 - acc: 0.7629 - val_loss: 1.2455 - val_acc: 0.5678\n",
      "Epoch 26/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.5882 - acc: 0.7467 - val_loss: 1.1973 - val_acc: 0.5283\n",
      "Epoch 27/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.5545 - acc: 0.7743 - val_loss: 1.3114 - val_acc: 0.5385\n",
      "Epoch 28/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.5101 - acc: 0.7900 - val_loss: 1.3921 - val_acc: 0.5516\n",
      "Epoch 29/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.5026 - acc: 0.7895 - val_loss: 1.6370 - val_acc: 0.5304\n",
      "Epoch 30/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.4998 - acc: 0.7910 - val_loss: 1.2663 - val_acc: 0.5729\n",
      "Epoch 31/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.4721 - acc: 0.8072 - val_loss: 1.4161 - val_acc: 0.5617\n",
      "Epoch 32/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.4820 - acc: 0.8004 - val_loss: 1.5897 - val_acc: 0.5283\n",
      "Epoch 33/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.4290 - acc: 0.8265 - val_loss: 1.5733 - val_acc: 0.5617\n",
      "Epoch 34/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.4617 - acc: 0.8136 - val_loss: 1.5301 - val_acc: 0.5192\n",
      "Epoch 35/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.4252 - acc: 0.8247 - val_loss: 1.4731 - val_acc: 0.5830\n",
      "Epoch 36/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.3798 - acc: 0.8475 - val_loss: 1.5648 - val_acc: 0.5648.847\n",
      "Epoch 37/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.4233 - acc: 0.8184 - val_loss: 1.5618 - val_acc: 0.5385\n",
      "Epoch 38/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.3683 - acc: 0.8513 - val_loss: 1.6681 - val_acc: 0.5344.85 - ETA: 3s - loss: 0.3683 - ETA: 0s - loss: 0.3724 - acc: 0.84\n",
      "Epoch 39/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.3508 - acc: 0.8546 - val_loss: 1.6856 - val_acc: 0.5688\n",
      "Epoch 40/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.3679 - acc: 0.8569 - val_loss: 1.8138 - val_acc: 0.5030\n",
      "Epoch 41/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.3443 - acc: 0.8587 - val_loss: 1.7649 - val_acc: 0.5283.8\n",
      "Epoch 42/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.3260 - acc: 0.8690 - val_loss: 1.7914 - val_acc: 0.5466\n",
      "Epoch 43/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.3156 - acc: 0.8723 - val_loss: 1.9257 - val_acc: 0.5668\n",
      "Epoch 44/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.3332 - acc: 0.8708 - val_loss: 2.1138 - val_acc: 0.5334\n",
      "Epoch 45/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2909 - acc: 0.8835 - val_loss: 2.0895 - val_acc: 0.5688\n",
      "Epoch 46/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2737 - acc: 0.8901 - val_loss: 1.8584 - val_acc: 0.5425\n",
      "Epoch 47/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2554 - acc: 0.8969 - val_loss: 2.0528 - val_acc: 0.5374\n",
      "Epoch 48/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2630 - acc: 0.8994 - val_loss: 2.0890 - val_acc: 0.5486\n",
      "Epoch 49/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2405 - acc: 0.9070 - val_loss: 2.0799 - val_acc: 0.5698\n",
      "Epoch 50/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2714 - acc: 0.8903 - val_loss: 2.2929 - val_acc: 0.5030\n",
      "Epoch 51/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2534 - acc: 0.8984 - val_loss: 2.2706 - val_acc: 0.5273\n",
      "Epoch 52/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2434 - acc: 0.9012 - val_loss: 2.1469 - val_acc: 0.5719\n",
      "Epoch 53/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2476 - acc: 0.8984 - val_loss: 2.4041 - val_acc: 0.5253\n",
      "Epoch 54/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2592 - acc: 0.8974 - val_loss: 2.4869 - val_acc: 0.5354\n",
      "Epoch 55/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2208 - acc: 0.9144 - val_loss: 2.0973 - val_acc: 0.5617\n",
      "Epoch 56/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2138 - acc: 0.9177 - val_loss: 2.5289 - val_acc: 0.5547\n",
      "Epoch 57/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.1860 - acc: 0.9250 - val_loss: 2.3743 - val_acc: 0.5253\n",
      "Epoch 58/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2031 - acc: 0.9255 - val_loss: 2.5243 - val_acc: 0.5304\n",
      "Epoch 59/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2266 - acc: 0.9098 - val_loss: 2.5482 - val_acc: 0.5172\n",
      "Epoch 60/60\n",
      "3948/3948 [==============================] - 13s - loss: 0.2395 - acc: 0.9050 - val_loss: 2.2495 - val_acc: 0.5506\n"
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train_speech,x_train_mocap], Y, \n",
    "                 batch_size=64, nb_epoch=60, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers, constraints, initializers, activations\n",
    "from keras.layers.recurrent import Recurrent, _time_distributed_dense\n",
    "from keras.engine import InputSpec\n",
    "\n",
    "tfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n",
    "\n",
    "class AttentionDecoder(Recurrent):\n",
    "\n",
    "    def __init__(self, units, output_dim,\n",
    "                 activation='tanh',\n",
    "                 return_probabilities=False,\n",
    "                 name='AttentionDecoder',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 recurrent_initializer='orthogonal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Implements an AttentionDecoder that takes in a sequence encoded by an\n",
    "        encoder and outputs the decoded states\n",
    "        :param units: dimension of the hidden state and the attention matrices\n",
    "        :param output_dim: the number of labels in the output space\n",
    "\n",
    "        references:\n",
    "            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio.\n",
    "            \"Neural machine translation by jointly learning to align and translate.\"\n",
    "            arXiv preprint arXiv:1409.0473 (2014).\n",
    "        \"\"\"\n",
    "        self.units = units\n",
    "        self.output_dim = output_dim\n",
    "        self.return_probabilities = return_probabilities\n",
    "        self.activation = activations.get(activation)\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.recurrent_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "        self.name = name\n",
    "        self.return_sequences = True  # must return sequences\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n",
    "          for model details that correspond to the matrices here.\n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_size, self.timesteps, self.input_dim = input_shape\n",
    "\n",
    "        if self.stateful:\n",
    "            super(AttentionDecoder, self).reset_states()\n",
    "\n",
    "        self.states = [None, None]  # y, s\n",
    "\n",
    "        \"\"\"\n",
    "            Matrices for creating the context vector\n",
    "        \"\"\"\n",
    "\n",
    "        self.V_a = self.add_weight(shape=(self.units,),\n",
    "                                   name='V_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.W_a = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='W_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='U_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.b_a = self.add_weight(shape=(self.units,),\n",
    "                                   name='b_a',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "        \"\"\"\n",
    "            Matrices for the r (reset) gate\n",
    "        \"\"\"\n",
    "        self.C_r = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='C_r',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_r = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='U_r',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_r = self.add_weight(shape=(self.output_dim, self.units),\n",
    "                                   name='W_r',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_r = self.add_weight(shape=(self.units, ),\n",
    "                                   name='b_r',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "\n",
    "        \"\"\"\n",
    "            Matrices for the z (update) gate\n",
    "        \"\"\"\n",
    "        self.C_z = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='C_z',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_z = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='U_z',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_z = self.add_weight(shape=(self.output_dim, self.units),\n",
    "                                   name='W_z',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_z = self.add_weight(shape=(self.units, ),\n",
    "                                   name='b_z',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "        \"\"\"\n",
    "            Matrices for the proposal\n",
    "        \"\"\"\n",
    "        self.C_p = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='C_p',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_p = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='U_p',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_p = self.add_weight(shape=(self.output_dim, self.units),\n",
    "                                   name='W_p',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_p = self.add_weight(shape=(self.units, ),\n",
    "                                   name='b_p',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "        \"\"\"\n",
    "            Matrices for making the final prediction vector\n",
    "        \"\"\"\n",
    "        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
    "                                   name='C_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n",
    "                                   name='U_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n",
    "                                   name='W_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_o = self.add_weight(shape=(self.output_dim, ),\n",
    "                                   name='b_o',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "\n",
    "        # For creating the initial state:\n",
    "        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='W_s',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "\n",
    "        self.input_spec = [\n",
    "            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x):\n",
    "        # store the whole sequence so we can \"attend\" to it at each timestep\n",
    "        self.x_seq = x\n",
    "\n",
    "        # apply the a dense layer over the time dimension of the sequence\n",
    "        # do it here because it doesn't depend on any previous steps\n",
    "        # thefore we can save computation time:\n",
    "        self._uxpb = _time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n",
    "                                             input_dim=self.input_dim,\n",
    "                                             timesteps=self.timesteps,\n",
    "                                             output_dim=self.units)\n",
    "\n",
    "        return super(AttentionDecoder, self).call(x)\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # apply the matrix on the first time step to get the initial s0.\n",
    "        s0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n",
    "\n",
    "        # from keras.layers.recurrent to initialize a vector of (batchsize,\n",
    "        # output_dim)\n",
    "        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n",
    "        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n",
    "        y0 = K.expand_dims(y0)  # (samples, 1)\n",
    "        y0 = K.tile(y0, [1, self.output_dim])\n",
    "\n",
    "        return [y0, s0]\n",
    "\n",
    "    def step(self, x, states):\n",
    "\n",
    "        ytm, stm = states\n",
    "\n",
    "        # repeat the hidden state to the length of the sequence\n",
    "        _stm = K.repeat(stm, self.timesteps)\n",
    "\n",
    "        # now multiplty the weight matrix with the repeated hidden state\n",
    "        _Wxstm = K.dot(_stm, self.W_a)\n",
    "\n",
    "        # calculate the attention probabilities\n",
    "        # this relates how much other timesteps contributed to this one.\n",
    "        et = K.dot(activations.tanh(_Wxstm + self._uxpb),\n",
    "                   K.expand_dims(self.V_a))\n",
    "        at = K.exp(et)\n",
    "        at_sum = K.sum(at, axis=1)\n",
    "        at_sum_repeated = K.repeat(at_sum, self.timesteps)\n",
    "        at /= at_sum_repeated  # vector of size (batchsize, timesteps, 1)\n",
    "\n",
    "        # calculate the context vector\n",
    "        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
    "        # ~~~> calculate new hidden state\n",
    "        # first calculate the \"r\" gate:\n",
    "\n",
    "        rt = activations.sigmoid(\n",
    "            K.dot(ytm, self.W_r)\n",
    "            + K.dot(stm, self.U_r)\n",
    "            + K.dot(context, self.C_r)\n",
    "            + self.b_r)\n",
    "\n",
    "        # now calculate the \"z\" gate\n",
    "        zt = activations.sigmoid(\n",
    "            K.dot(ytm, self.W_z)\n",
    "            + K.dot(stm, self.U_z)\n",
    "            + K.dot(context, self.C_z)\n",
    "            + self.b_z)\n",
    "\n",
    "        # calculate the proposal hidden state:\n",
    "        s_tp = activations.tanh(\n",
    "            K.dot(ytm, self.W_p)\n",
    "            + K.dot((rt * stm), self.U_p)\n",
    "            + K.dot(context, self.C_p)\n",
    "            + self.b_p)\n",
    "\n",
    "        # new hidden state:\n",
    "        st = (1-zt)*stm + zt * s_tp\n",
    "\n",
    "        yt = activations.softmax(\n",
    "            K.dot(ytm, self.W_o)\n",
    "            + K.dot(stm, self.U_o)\n",
    "            + K.dot(context, self.C_o)\n",
    "            + self.b_o)\n",
    "\n",
    "        if self.return_probabilities:\n",
    "            return at, [yt, st]\n",
    "        else:\n",
    "            return yt, [yt, st]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"\n",
    "            For Keras internal compatability checking\n",
    "        \"\"\"\n",
    "        if self.return_probabilities:\n",
    "            return (None, self.timesteps, self.timesteps)\n",
    "        else:\n",
    "            return (None, self.timesteps, self.output_dim)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "            For rebuilding models on load time.\n",
    "        \"\"\"\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'units': self.units,\n",
    "            'return_probabilities': self.return_probabilities\n",
    "        }\n",
    "        base_config = super(AttentionDecoder, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_23 (LSTM)               (None, 100, 128)          83456     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 100, 128)          246528    \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 256)               3277056   \n",
      "=================================================================\n",
      "Total params: 3,607,040\n",
      "Trainable params: 3,607,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 500, 256)          570368    \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 1,982,572\n",
      "Trainable params: 1,982,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 100, 95, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 50, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 25, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 13, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 256)               1376512   \n",
      "=================================================================\n",
      "Total params: 1,653,696\n",
      "Trainable params: 1,653,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_21 (Merge)             (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 7,441,200\n",
      "Trainable params: 7,441,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, strides=(2, 2), padding=\"same\", input_shape=(200, 189,...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:40: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "\n",
    "model_text.add(LSTM(256, return_sequences=True))\n",
    "model_text.add(LSTM(256, return_sequences=False))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(LSTM(128, return_sequences=True, input_shape=(100, 34)))\n",
    "model_speech.add(AttentionDecoder(128,128))\n",
    "model_speech.add(Flatten())\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "model_mocap = Sequential()\n",
    "model_mocap.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 189, 1)))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Flatten())\n",
    "model_mocap.add(Dense(256))\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech, model_mocap], mode='concat'))\n",
    "\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_mocap.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3948 samples, validate on 988 samples\n",
      "Epoch 1/30\n",
      "3948/3948 [==============================] - 134s - loss: 1.4364 - acc: 0.3652 - val_loss: 1.2002 - val_acc: 0.5040\n",
      "Epoch 2/30\n",
      "3948/3948 [==============================] - 131s - loss: 1.0254 - acc: 0.5795 - val_loss: 1.0986 - val_acc: 0.5567\n",
      "Epoch 3/30\n",
      "3948/3948 [==============================] - 131s - loss: 0.7341 - acc: 0.7054 - val_loss: 0.9238 - val_acc: 0.6569\n",
      "Epoch 4/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.5781 - acc: 0.7781 - val_loss: 0.9490 - val_acc: 0.6377\n",
      "Epoch 5/30\n",
      "3948/3948 [==============================] - 131s - loss: 0.4860 - acc: 0.8078 - val_loss: 0.8963 - val_acc: 0.6731\n",
      "Epoch 6/30\n",
      "3948/3948 [==============================] - 131s - loss: 0.3813 - acc: 0.8549 - val_loss: 0.9789 - val_acc: 0.6781\n",
      "Epoch 7/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.3127 - acc: 0.8756 - val_loss: 1.0113 - val_acc: 0.6640\n",
      "Epoch 8/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.2846 - acc: 0.8956 - val_loss: 1.1080 - val_acc: 0.6609\n",
      "Epoch 9/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.2432 - acc: 0.9035 - val_loss: 1.1896 - val_acc: 0.6508\n",
      "Epoch 10/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.2102 - acc: 0.9225 - val_loss: 1.2862 - val_acc: 0.6609\n",
      "Epoch 11/30\n",
      "3948/3948 [==============================] - 131s - loss: 0.2166 - acc: 0.9162 - val_loss: 1.2144 - val_acc: 0.6812\n",
      "Epoch 12/30\n",
      "3948/3948 [==============================] - 131s - loss: 0.1831 - acc: 0.9301 - val_loss: 1.4422 - val_acc: 0.6741\n",
      "Epoch 13/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.1778 - acc: 0.9296 - val_loss: 1.3357 - val_acc: 0.6498\n",
      "Epoch 14/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.1503 - acc: 0.9422 - val_loss: 1.5409 - val_acc: 0.6498\n",
      "Epoch 15/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.1502 - acc: 0.9369 - val_loss: 1.3683 - val_acc: 0.6893\n",
      "Epoch 16/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.1326 - acc: 0.9450 - val_loss: 1.6248 - val_acc: 0.6690\n",
      "Epoch 17/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.1290 - acc: 0.9506 - val_loss: 1.5428 - val_acc: 0.6842\n",
      "Epoch 18/30\n",
      "3948/3948 [==============================] - 133s - loss: 0.1086 - acc: 0.9554 - val_loss: 1.8272 - val_acc: 0.6599\n",
      "Epoch 19/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.1165 - acc: 0.9524 - val_loss: 1.8900 - val_acc: 0.6771\n",
      "Epoch 20/30\n",
      "3948/3948 [==============================] - 133s - loss: 0.1070 - acc: 0.9567 - val_loss: 1.5875 - val_acc: 0.6751\n",
      "Epoch 21/30\n",
      "3948/3948 [==============================] - 133s - loss: 0.1016 - acc: 0.9595 - val_loss: 2.0949 - val_acc: 0.6518\n",
      "Epoch 22/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.1098 - acc: 0.9547 - val_loss: 2.0732 - val_acc: 0.6791\n",
      "Epoch 23/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.0873 - acc: 0.9656 - val_loss: 2.1321 - val_acc: 0.6609\n",
      "Epoch 24/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.0970 - acc: 0.9612 - val_loss: 1.8830 - val_acc: 0.6609\n",
      "Epoch 25/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.0806 - acc: 0.9666 - val_loss: 2.0926 - val_acc: 0.6700\n",
      "Epoch 26/30\n",
      "3948/3948 [==============================] - 133s - loss: 0.0899 - acc: 0.9615 - val_loss: 1.8692 - val_acc: 0.6842\n",
      "Epoch 27/30\n",
      "3948/3948 [==============================] - 133s - loss: 0.0844 - acc: 0.9678 - val_loss: 2.0203 - val_acc: 0.6852\n",
      "Epoch 28/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.0697 - acc: 0.9724 - val_loss: 2.2676 - val_acc: 0.6680\n",
      "Epoch 29/30\n",
      "3948/3948 [==============================] - 131s - loss: 0.0834 - acc: 0.9648 - val_loss: 2.1832 - val_acc: 0.6842\n",
      "Epoch 30/30\n",
      "3948/3948 [==============================] - 132s - loss: 0.0836 - acc: 0.9666 - val_loss: 2.1394 - val_acc: 0.6731\n"
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([x_train_text,x_train_speech,x_train_mocap], Y, \n",
    "                 batch_size=64, nb_epoch=30, verbose=1, \n",
    "                 validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
