{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import wave\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import LSTM, Input, Flatten, Merge, Embedding, Convolution1D,Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "from features import *\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n",
    "data_path = code_path + \"/../data/sessions/\"\n",
    "sessions = ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']\n",
    "framerate = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(data_path + '/../'+'data_collected.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for ses_mod in data2:\n",
    "    text.append(ses_mod['transcription'])\n",
    "    \n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "\n",
    "token_tr_X = tokenizer.texts_to_sequences(text)\n",
    "x_train_text = []\n",
    "\n",
    "x_train_text = sequence.pad_sequences(token_tr_X, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2736 unique tokens\n",
      "/home/samarth/emotion_recognition-master/code/../data/sessions/../glove.42B.300d.txt\n",
      "G Word embeddings: 1917494\n",
      "G Null word embeddings: 90\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "file_loc = data_path + '../glove.42B.300d.txt'\n",
    "\n",
    "print (file_loc)\n",
    "\n",
    "gembeddings_index = {}\n",
    "with codecs.open(file_loc, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        gembedding = np.asarray(values[1:], dtype='float32')\n",
    "        gembeddings_index[word] = gembedding\n",
    "#\n",
    "f.close()\n",
    "print('G Word embeddings:', len(gembeddings_index))\n",
    "\n",
    "nb_words = len(word_index) +1\n",
    "g_word_embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    gembedding_vector = gembeddings_index.get(word)\n",
    "    if gembedding_vector is not None:\n",
    "        g_word_embedding_matrix[i] = gembedding_vector\n",
    "        \n",
    "print('G Null word embeddings: %d' % np.sum(np.sum(g_word_embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(frames, freq, options):\n",
    "    window_sec = 0.2\n",
    "    window_n = int(freq * window_sec)\n",
    "\n",
    "    st_f = stFeatureExtraction(frames, freq, window_n, window_n / 2)\n",
    "\n",
    "    if st_f.shape[1] > 2:\n",
    "        i0 = 1\n",
    "        i1 = st_f.shape[1] - 1\n",
    "        if i1 - i0 < 1:\n",
    "            i1 = i0 + 1\n",
    "        \n",
    "        deriv_st_f = np.zeros((st_f.shape[0], i1 - i0), dtype=float)\n",
    "        for i in range(i0, i1):\n",
    "            i_left = i - 1\n",
    "            i_right = i + 1\n",
    "            deriv_st_f[:st_f.shape[0], i - i0] = st_f[:, i]\n",
    "        return deriv_st_f\n",
    "    elif st_f.shape[1] == 2:\n",
    "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "        return deriv_st_f\n",
    "    else:\n",
    "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "        return deriv_st_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4936, 100, 34)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_speech = []\n",
    "\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['signal']\n",
    "    st_features = calculate_features(x_head, framerate, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "    x_train_speech.append( st_features.T )\n",
    "    counter+=1\n",
    "    if(counter%100==0):\n",
    "        print(counter)\n",
    "    \n",
    "x_train_speech = np.array(x_train_speech)\n",
    "x_train_speech.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 200, 189, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_mocap = []\n",
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    x_head = ses_mod['mocap_head']\n",
    "    if(x_head.shape != (200,18)):\n",
    "        x_head = np.zeros((200,18))   \n",
    "    x_head[np.isnan(x_head)]=0\n",
    "    x_hand = ses_mod['mocap_hand']\n",
    "    if(x_hand.shape != (200,6)):\n",
    "        x_hand = np.zeros((200,6))   \n",
    "    x_hand[np.isnan(x_hand)]=0\n",
    "    x_rot = ses_mod['mocap_rot']\n",
    "    if(x_rot.shape != (200,165)):\n",
    "        x_rot = np.zeros((200,165))   \n",
    "    x_rot[np.isnan(x_rot)]=0\n",
    "    x_mocap = np.concatenate((x_head, x_hand), axis=1)\n",
    "    x_mocap = np.concatenate((x_mocap, x_rot), axis=1)\n",
    "    x_train_mocap.append( x_mocap )\n",
    "    \n",
    "x_train_mocap = np.array(x_train_mocap)\n",
    "x_train_mocap = x_train_mocap.reshape(-1,200,189,1)\n",
    "x_train_mocap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4936, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[]\n",
    "for ses_mod in data2:\n",
    "    Y.append(ses_mod['emotion'])\n",
    "    \n",
    "Y = label_binarize(Y,emotions_used)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3838"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "for ses_mod in data2:\n",
    "    if (ses_mod['id'][:5]==\"Ses05\"):\n",
    "        break\n",
    "    counter+=1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_sp = x_train_speech[:3838]\n",
    "xtest_sp = x_train_speech[3838:]\n",
    "xtrain_tx = x_train_text[:3838]\n",
    "xtest_tx = x_train_text[3838:]\n",
    "ytrain_sp = Y[:3838]\n",
    "ytest_sp = Y[3838:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 3400)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              3482624   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               262400    \n",
      "=================================================================\n",
      "Total params: 3,745,024\n",
      "Trainable params: 3,745,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 500, 256)          570368    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 1,982,572\n",
      "Trainable params: 1,982,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_2 (Merge)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 5,859,952\n",
      "Trainable params: 5,859,952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:23: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "\n",
    "model_text.add(LSTM(256, return_sequences=True))\n",
    "model_text.add(LSTM(256, return_sequences=False))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(100, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech], mode='concat'))\n",
    "\n",
    "model_combined.add(Activation('relu'))\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3838 samples, validate on 1098 samples\n",
      "Epoch 1/20\n",
      "3838/3838 [==============================] - 97s - loss: 1.4254 - acc: 0.3869 - val_loss: 1.3605 - val_acc: 0.4372\n",
      "Epoch 2/20\n",
      "3838/3838 [==============================] - 94s - loss: 0.9943 - acc: 0.5703 - val_loss: 1.1100 - val_acc: 0.5546\n",
      "Epoch 3/20\n",
      "3838/3838 [==============================] - 93s - loss: 0.7385 - acc: 0.7009 - val_loss: 0.8987 - val_acc: 0.6475\n",
      "Epoch 4/20\n",
      "3838/3838 [==============================] - 95s - loss: 0.5597 - acc: 0.7861 - val_loss: 0.9326 - val_acc: 0.6621\n",
      "Epoch 5/20\n",
      "3838/3838 [==============================] - 94s - loss: 0.4500 - acc: 0.8288 - val_loss: 1.0634 - val_acc: 0.6639\n",
      "Epoch 6/20\n",
      "3838/3838 [==============================] - 95s - loss: 0.3609 - acc: 0.8653 - val_loss: 1.0794 - val_acc: 0.6676\n",
      "Epoch 7/20\n",
      "3838/3838 [==============================] - 94s - loss: 0.3208 - acc: 0.8794 - val_loss: 1.0621 - val_acc: 0.6730\n",
      "Epoch 8/20\n",
      "3838/3838 [==============================] - 97s - loss: 0.2881 - acc: 0.8929 - val_loss: 1.0903 - val_acc: 0.6694\n",
      "Epoch 9/20\n",
      "3838/3838 [==============================] - 95s - loss: 0.2188 - acc: 0.9138 - val_loss: 1.3055 - val_acc: 0.6612\n",
      "Epoch 10/20\n",
      "3838/3838 [==============================] - 102s - loss: 0.1952 - acc: 0.9263 - val_loss: 1.3017 - val_acc: 0.6730\n",
      "Epoch 11/20\n",
      "3838/3838 [==============================] - 100s - loss: 0.1751 - acc: 0.9333 - val_loss: 1.3074 - val_acc: 0.6840\n",
      "Epoch 12/20\n",
      "3838/3838 [==============================] - 100s - loss: 0.1631 - acc: 0.9367 - val_loss: 1.5168 - val_acc: 0.6703\n",
      "Epoch 13/20\n",
      "3838/3838 [==============================] - 99s - loss: 0.1508 - acc: 0.9440 - val_loss: 1.6049 - val_acc: 0.6639\n",
      "Epoch 14/20\n",
      "3838/3838 [==============================] - 95s - loss: 0.1286 - acc: 0.9513 - val_loss: 1.4978 - val_acc: 0.6840\n",
      "Epoch 15/20\n",
      "3838/3838 [==============================] - 94s - loss: 0.1223 - acc: 0.9523 - val_loss: 1.5830 - val_acc: 0.6658\n",
      "Epoch 16/20\n",
      "3838/3838 [==============================] - 94s - loss: 0.1297 - acc: 0.9484 - val_loss: 1.4483 - val_acc: 0.6630\n",
      "Epoch 17/20\n",
      "3838/3838 [==============================] - 101s - loss: 0.1100 - acc: 0.9591 - val_loss: 1.9392 - val_acc: 0.6585\n",
      "Epoch 18/20\n",
      "3838/3838 [==============================] - 100s - loss: 0.0855 - acc: 0.9666 - val_loss: 1.8291 - val_acc: 0.6721\n",
      "Epoch 19/20\n",
      "3838/3838 [==============================] - 97s - loss: 0.0835 - acc: 0.9669 - val_loss: 2.1789 - val_acc: 0.6576\n",
      "Epoch 20/20\n",
      "3838/3838 [==============================] - 93s - loss: 0.1444 - acc: 0.9437 - val_loss: 2.1140 - val_acc: 0.6412\n"
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([xtrain_tx,xtrain_sp], ytrain_sp, \n",
    "                 batch_size=64, nb_epoch=20, verbose=1, \n",
    "                 validation_data=([xtest_tx,xtest_sp], ytest_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_mo = x_train_mocap[:3838]\n",
    "xtest_mo = x_train_mocap[3838:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, strides=(2, 2), input_shape=(200, 189,..., padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 3400)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1024)              3482624   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               262400    \n",
      "=================================================================\n",
      "Total params: 3,745,024\n",
      "Trainable params: 3,745,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 500, 256)          570368    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 1,982,572\n",
      "Trainable params: 1,982,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 95, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               1376512   \n",
      "=================================================================\n",
      "Total params: 1,653,696\n",
      "Trainable params: 1,653,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_3 (Merge)              (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 7,579,184\n",
      "Trainable params: 7,579,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "\n",
    "model_text.add(LSTM(256, return_sequences=True))\n",
    "model_text.add(LSTM(256, return_sequences=False))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(100, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "model_mocap = Sequential()\n",
    "model_mocap.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 189, 1)))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Flatten())\n",
    "model_mocap.add(Dense(256))\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech, model_mocap], mode='concat'))\n",
    "\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_mocap.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3838 samples, validate on 1098 samples\n",
      "Epoch 1/20\n",
      "3838/3838 [==============================] - 109s - loss: 2.3534 - acc: 0.3377 - val_loss: 1.2499 - val_acc: 0.4344\n",
      "Epoch 2/20\n",
      "3838/3838 [==============================] - 101s - loss: 1.0247 - acc: 0.5555 - val_loss: 0.9496 - val_acc: 0.6148\n",
      "Epoch 3/20\n",
      "3838/3838 [==============================] - 101s - loss: 0.7283 - acc: 0.7113 - val_loss: 0.8120 - val_acc: 0.6794\n",
      "Epoch 4/20\n",
      "3838/3838 [==============================] - 100s - loss: 0.5554 - acc: 0.7850 - val_loss: 0.8734 - val_acc: 0.6566\n",
      "Epoch 5/20\n",
      "3838/3838 [==============================] - 104s - loss: 0.4523 - acc: 0.8273 - val_loss: 0.9274 - val_acc: 0.6603\n",
      "Epoch 6/20\n",
      "3838/3838 [==============================] - 108s - loss: 0.3558 - acc: 0.8658 - val_loss: 1.0546 - val_acc: 0.6576\n",
      "Epoch 7/20\n",
      "3838/3838 [==============================] - 109s - loss: 0.3070 - acc: 0.8825 - val_loss: 1.0860 - val_acc: 0.6767\n",
      "Epoch 8/20\n",
      "3838/3838 [==============================] - 106s - loss: 0.2597 - acc: 0.9002 - val_loss: 1.3458 - val_acc: 0.6421\n",
      "Epoch 9/20\n",
      "3838/3838 [==============================] - 103s - loss: 0.2288 - acc: 0.9093 - val_loss: 1.2096 - val_acc: 0.6703\n",
      "Epoch 10/20\n",
      "3838/3838 [==============================] - 100s - loss: 0.2013 - acc: 0.9294 - val_loss: 1.1858 - val_acc: 0.6767\n",
      "Epoch 11/20\n",
      "3838/3838 [==============================] - 99s - loss: 0.1876 - acc: 0.9281 - val_loss: 1.3649 - val_acc: 0.6648\n",
      "Epoch 12/20\n",
      "3838/3838 [==============================] - 97s - loss: 0.1543 - acc: 0.9406 - val_loss: 1.4593 - val_acc: 0.6721\n",
      "Epoch 13/20\n",
      "3838/3838 [==============================] - 98s - loss: 0.1393 - acc: 0.9429 - val_loss: 1.4796 - val_acc: 0.6685\n",
      "Epoch 14/20\n",
      "3838/3838 [==============================] - 97s - loss: 0.1387 - acc: 0.9458 - val_loss: 1.7812 - val_acc: 0.6566\n",
      "Epoch 15/20\n",
      "3838/3838 [==============================] - 99s - loss: 0.1696 - acc: 0.9367 - val_loss: 1.6309 - val_acc: 0.6667\n",
      "Epoch 16/20\n",
      "3838/3838 [==============================] - 99s - loss: 0.1132 - acc: 0.9581 - val_loss: 1.7458 - val_acc: 0.6667\n",
      "Epoch 17/20\n",
      "3838/3838 [==============================] - 100s - loss: 0.1028 - acc: 0.9583 - val_loss: 1.9641 - val_acc: 0.6585\n",
      "Epoch 18/20\n",
      "3838/3838 [==============================] - 102s - loss: 0.0839 - acc: 0.9651 - val_loss: 2.0139 - val_acc: 0.6621\n",
      "Epoch 19/20\n",
      "3838/3838 [==============================] - 102s - loss: 0.0861 - acc: 0.9653 - val_loss: 1.8743 - val_acc: 0.6658\n",
      "Epoch 20/20\n",
      "3838/3838 [==============================] - 102s - loss: 0.0881 - acc: 0.9672 - val_loss: 1.8280 - val_acc: 0.6703\n"
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([xtrain_tx,xtrain_sp,xtrain_mo], ytrain_sp, \n",
    "                 batch_size=64, nb_epoch=20, verbose=1, \n",
    "                 validation_data=([xtest_tx,xtest_sp,xtest_mo], ytest_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mocap2 = x_train_mocap.reshape(-1,200,189)\n",
    "xtrain_mo = x_train_mocap2[:3838]\n",
    "xtest_mo = x_train_mocap2[3838:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 3400)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1024)              3482624   \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               262400    \n",
      "=================================================================\n",
      "Total params: 3,745,024\n",
      "Trainable params: 3,745,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 500, 256)          570368    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 1,982,572\n",
      "Trainable params: 1,982,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 200, 256)          456704    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 1,047,808\n",
      "Trainable params: 1,047,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_4 (Merge)              (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 6,973,296\n",
      "Trainable params: 6,973,296\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "\n",
    "model_text.add(LSTM(256, return_sequences=True))\n",
    "model_text.add(LSTM(256, return_sequences=False))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(Flatten(input_shape=(100, 34)))\n",
    "model_speech.add(Dense(1024))\n",
    "model_speech.add(Activation('relu'))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "model_mocap = Sequential()\n",
    "model_mocap.add(LSTM(256, return_sequences=True, input_shape=(200, 189)))\n",
    "model_mocap.add(LSTM(256, return_sequences=False))\n",
    "model_mocap.add(Dense(256))\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech, model_mocap], mode='concat'))\n",
    "\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_mocap.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3838 samples, validate on 1098 samples\n",
      "Epoch 1/20\n",
      "3838/3838 [==============================] - 135s - loss: 1.5098 - acc: 0.3794 - val_loss: 1.2127 - val_acc: 0.4572\n",
      "Epoch 2/20\n",
      "3838/3838 [==============================] - 132s - loss: 1.0074 - acc: 0.5732 - val_loss: 0.9689 - val_acc: 0.5984\n",
      "Epoch 3/20\n",
      "3838/3838 [==============================] - 131s - loss: 0.7328 - acc: 0.7084 - val_loss: 0.9150 - val_acc: 0.6330\n",
      "Epoch 4/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.5839 - acc: 0.7723 - val_loss: 0.8540 - val_acc: 0.6730\n",
      "Epoch 5/20\n",
      "3838/3838 [==============================] - 132s - loss: 0.4515 - acc: 0.8286 - val_loss: 0.9827 - val_acc: 0.6667\n",
      "Epoch 6/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.3672 - acc: 0.8559 - val_loss: 0.9922 - val_acc: 0.6730\n",
      "Epoch 7/20\n",
      "3838/3838 [==============================] - 132s - loss: 0.3202 - acc: 0.8757 - val_loss: 1.0905 - val_acc: 0.6730\n",
      "Epoch 8/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.2622 - acc: 0.9010 - val_loss: 1.0578 - val_acc: 0.6858\n",
      "Epoch 9/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.2252 - acc: 0.9169 - val_loss: 1.2785 - val_acc: 0.6785\n",
      "Epoch 10/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.1989 - acc: 0.9257 - val_loss: 1.2943 - val_acc: 0.6557\n",
      "Epoch 11/20\n",
      "3838/3838 [==============================] - 129s - loss: 0.2019 - acc: 0.9247 - val_loss: 1.3847 - val_acc: 0.6658\n",
      "Epoch 12/20\n",
      "3838/3838 [==============================] - 130s - loss: 0.1568 - acc: 0.9440 - val_loss: 1.4129 - val_acc: 0.6603\n",
      "Epoch 13/20\n",
      "3838/3838 [==============================] - 132s - loss: 0.1599 - acc: 0.9409 - val_loss: 1.5436 - val_acc: 0.6466\n",
      "Epoch 14/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.1425 - acc: 0.9461 - val_loss: 1.7256 - val_acc: 0.6521\n",
      "Epoch 15/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.1347 - acc: 0.9492 - val_loss: 1.7604 - val_acc: 0.6612\n",
      "Epoch 16/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.1132 - acc: 0.9581 - val_loss: 1.7174 - val_acc: 0.6603\n",
      "Epoch 17/20\n",
      "3838/3838 [==============================] - 132s - loss: 0.1005 - acc: 0.9643 - val_loss: 2.2605 - val_acc: 0.6393\n",
      "Epoch 18/20\n",
      " 960/3838 [======>.......................] - ETA: 93s - loss: 0.0934 - acc: 0.9656"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-246df15326f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model_combined.fit([xtrain_tx,xtrain_sp,xtrain_mo], ytrain_sp, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_data=([xtest_tx,xtest_sp,xtest_mo], ytest_sp))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([xtrain_tx,xtrain_sp,xtrain_mo], ytrain_sp, \n",
    "                 batch_size=64, nb_epoch=20, verbose=1, \n",
    "                 validation_data=([xtest_tx,xtest_sp,xtest_mo], ytest_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import regularizers, constraints, initializers, activations\n",
    "from keras.layers.recurrent import Recurrent, _time_distributed_dense\n",
    "from keras.engine import InputSpec\n",
    "\n",
    "tfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n",
    "\n",
    "class AttentionDecoder(Recurrent):\n",
    "\n",
    "    def __init__(self, units, output_dim,\n",
    "                 activation='tanh',\n",
    "                 return_probabilities=False,\n",
    "                 name='AttentionDecoder',\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 recurrent_initializer='orthogonal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Implements an AttentionDecoder that takes in a sequence encoded by an\n",
    "        encoder and outputs the decoded states\n",
    "        :param units: dimension of the hidden state and the attention matrices\n",
    "        :param output_dim: the number of labels in the output space\n",
    "\n",
    "        references:\n",
    "            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio.\n",
    "            \"Neural machine translation by jointly learning to align and translate.\"\n",
    "            arXiv preprint arXiv:1409.0473 (2014).\n",
    "        \"\"\"\n",
    "        self.units = units\n",
    "        self.output_dim = output_dim\n",
    "        self.return_probabilities = return_probabilities\n",
    "        self.activation = activations.get(activation)\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.recurrent_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "        self.name = name\n",
    "        self.return_sequences = True  # must return sequences\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n",
    "          for model details that correspond to the matrices here.\n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_size, self.timesteps, self.input_dim = input_shape\n",
    "\n",
    "        if self.stateful:\n",
    "            super(AttentionDecoder, self).reset_states()\n",
    "\n",
    "        self.states = [None, None]  # y, s\n",
    "\n",
    "        \"\"\"\n",
    "            Matrices for creating the context vector\n",
    "        \"\"\"\n",
    "\n",
    "        self.V_a = self.add_weight(shape=(self.units,),\n",
    "                                   name='V_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.W_a = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='W_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='U_a',\n",
    "                                   initializer=self.kernel_initializer,\n",
    "                                   regularizer=self.kernel_regularizer,\n",
    "                                   constraint=self.kernel_constraint)\n",
    "        self.b_a = self.add_weight(shape=(self.units,),\n",
    "                                   name='b_a',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "        \"\"\"\n",
    "            Matrices for the r (reset) gate\n",
    "        \"\"\"\n",
    "        self.C_r = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='C_r',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_r = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='U_r',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_r = self.add_weight(shape=(self.output_dim, self.units),\n",
    "                                   name='W_r',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_r = self.add_weight(shape=(self.units, ),\n",
    "                                   name='b_r',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "\n",
    "        \"\"\"\n",
    "            Matrices for the z (update) gate\n",
    "        \"\"\"\n",
    "        self.C_z = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='C_z',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_z = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='U_z',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_z = self.add_weight(shape=(self.output_dim, self.units),\n",
    "                                   name='W_z',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_z = self.add_weight(shape=(self.units, ),\n",
    "                                   name='b_z',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "        \"\"\"\n",
    "            Matrices for the proposal\n",
    "        \"\"\"\n",
    "        self.C_p = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='C_p',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_p = self.add_weight(shape=(self.units, self.units),\n",
    "                                   name='U_p',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_p = self.add_weight(shape=(self.output_dim, self.units),\n",
    "                                   name='W_p',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_p = self.add_weight(shape=(self.units, ),\n",
    "                                   name='b_p',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "        \"\"\"\n",
    "            Matrices for making the final prediction vector\n",
    "        \"\"\"\n",
    "        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
    "                                   name='C_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n",
    "                                   name='U_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n",
    "                                   name='W_o',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "        self.b_o = self.add_weight(shape=(self.output_dim, ),\n",
    "                                   name='b_o',\n",
    "                                   initializer=self.bias_initializer,\n",
    "                                   regularizer=self.bias_regularizer,\n",
    "                                   constraint=self.bias_constraint)\n",
    "\n",
    "        # For creating the initial state:\n",
    "        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                   name='W_s',\n",
    "                                   initializer=self.recurrent_initializer,\n",
    "                                   regularizer=self.recurrent_regularizer,\n",
    "                                   constraint=self.recurrent_constraint)\n",
    "\n",
    "        self.input_spec = [\n",
    "            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x):\n",
    "        # store the whole sequence so we can \"attend\" to it at each timestep\n",
    "        self.x_seq = x\n",
    "\n",
    "        # apply the a dense layer over the time dimension of the sequence\n",
    "        # do it here because it doesn't depend on any previous steps\n",
    "        # thefore we can save computation time:\n",
    "        self._uxpb = _time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n",
    "                                             input_dim=self.input_dim,\n",
    "                                             timesteps=self.timesteps,\n",
    "                                             output_dim=self.units)\n",
    "\n",
    "        return super(AttentionDecoder, self).call(x)\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        # apply the matrix on the first time step to get the initial s0.\n",
    "        s0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n",
    "\n",
    "        # from keras.layers.recurrent to initialize a vector of (batchsize,\n",
    "        # output_dim)\n",
    "        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n",
    "        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n",
    "        y0 = K.expand_dims(y0)  # (samples, 1)\n",
    "        y0 = K.tile(y0, [1, self.output_dim])\n",
    "\n",
    "        return [y0, s0]\n",
    "\n",
    "    def step(self, x, states):\n",
    "\n",
    "        ytm, stm = states\n",
    "\n",
    "        # repeat the hidden state to the length of the sequence\n",
    "        _stm = K.repeat(stm, self.timesteps)\n",
    "\n",
    "        # now multiplty the weight matrix with the repeated hidden state\n",
    "        _Wxstm = K.dot(_stm, self.W_a)\n",
    "\n",
    "        # calculate the attention probabilities\n",
    "        # this relates how much other timesteps contributed to this one.\n",
    "        et = K.dot(activations.tanh(_Wxstm + self._uxpb),\n",
    "                   K.expand_dims(self.V_a))\n",
    "        at = K.exp(et)\n",
    "        at_sum = K.sum(at, axis=1)\n",
    "        at_sum_repeated = K.repeat(at_sum, self.timesteps)\n",
    "        at /= at_sum_repeated  # vector of size (batchsize, timesteps, 1)\n",
    "\n",
    "        # calculate the context vector\n",
    "        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n",
    "        # ~~~> calculate new hidden state\n",
    "        # first calculate the \"r\" gate:\n",
    "\n",
    "        rt = activations.sigmoid(\n",
    "            K.dot(ytm, self.W_r)\n",
    "            + K.dot(stm, self.U_r)\n",
    "            + K.dot(context, self.C_r)\n",
    "            + self.b_r)\n",
    "\n",
    "        # now calculate the \"z\" gate\n",
    "        zt = activations.sigmoid(\n",
    "            K.dot(ytm, self.W_z)\n",
    "            + K.dot(stm, self.U_z)\n",
    "            + K.dot(context, self.C_z)\n",
    "            + self.b_z)\n",
    "\n",
    "        # calculate the proposal hidden state:\n",
    "        s_tp = activations.tanh(\n",
    "            K.dot(ytm, self.W_p)\n",
    "            + K.dot((rt * stm), self.U_p)\n",
    "            + K.dot(context, self.C_p)\n",
    "            + self.b_p)\n",
    "\n",
    "        # new hidden state:\n",
    "        st = (1-zt)*stm + zt * s_tp\n",
    "\n",
    "        yt = activations.softmax(\n",
    "            K.dot(ytm, self.W_o)\n",
    "            + K.dot(stm, self.U_o)\n",
    "            + K.dot(context, self.C_o)\n",
    "            + self.b_o)\n",
    "\n",
    "        if self.return_probabilities:\n",
    "            return at, [yt, st]\n",
    "        else:\n",
    "            return yt, [yt, st]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"\n",
    "            For Keras internal compatability checking\n",
    "        \"\"\"\n",
    "        if self.return_probabilities:\n",
    "            return (None, self.timesteps, self.timesteps)\n",
    "        else:\n",
    "            return (None, self.timesteps, self.output_dim)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "            For rebuilding models on load time.\n",
    "        \"\"\"\n",
    "        config = {\n",
    "            'output_dim': self.output_dim,\n",
    "            'units': self.units,\n",
    "            'return_probabilities': self.return_probabilities\n",
    "        }\n",
    "        base_config = super(AttentionDecoder, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 100, 128)          83456     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 100, 128)          246528    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 100, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               3277056   \n",
      "=================================================================\n",
      "Total params: 3,607,040\n",
      "Trainable params: 3,607,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 300)          821100    \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 500, 256)          570368    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 500, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 1,982,572\n",
      "Trainable params: 1,982,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 100, 95, 32)       320       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 100, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 50, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 25, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 13, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 256)               1376512   \n",
      "=================================================================\n",
      "Total params: 1,653,696\n",
      "Trainable params: 1,653,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_5 (Merge)              (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 7,441,200\n",
      "Trainable params: 7,441,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model1 Built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, strides=(2, 2), input_shape=(200, 189,..., padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:44: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "model_text = Sequential()\n",
    "#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model_text.add(Embedding(nb_words,\n",
    "                    EMBEDDING_DIM,\n",
    "                    weights = [g_word_embedding_matrix],\n",
    "                    input_length = MAX_SEQUENCE_LENGTH,\n",
    "                    trainable = True))\n",
    "\n",
    "model_text.add(LSTM(256, return_sequences=True, recurrent_dropout = 0.2))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(LSTM(256, return_sequences=False, recurrent_dropout = 0.2))\n",
    "model_text.add(Dropout(0.2))\n",
    "model_text.add(Dense(256))\n",
    "\n",
    "\n",
    "model_speech = Sequential()\n",
    "model_speech.add(LSTM(128, return_sequences=True, input_shape=(100, 34), recurrent_dropout = 0.2))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(AttentionDecoder(128,128))\n",
    "model_speech.add(Dropout(0.2))\n",
    "model_speech.add(Flatten())\n",
    "model_speech.add(Dense(256))\n",
    "\n",
    "model_mocap = Sequential()\n",
    "model_mocap.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 189, 1)))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n",
    "model_mocap.add(Dropout(0.2))\n",
    "model_mocap.add(Activation('relu'))\n",
    "model_mocap.add(Flatten())\n",
    "model_mocap.add(Dense(256))\n",
    "\n",
    "model_combined = Sequential()\n",
    "model_combined.add(Merge([model_text, model_speech, model_mocap], mode='concat'))\n",
    "\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(256))\n",
    "model_combined.add(Activation('relu'))\n",
    "\n",
    "model_combined.add(Dense(4))\n",
    "model_combined.add(Activation('softmax'))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n",
    "\n",
    "## compille it here according to instructions\n",
    "\n",
    "#model.compile()\n",
    "model_speech.summary()\n",
    "model_text.summary()\n",
    "model_mocap.summary()\n",
    "model_combined.summary()\n",
    "\n",
    "print(\"Model1 Built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_mo = x_train_mocap[:3838]\n",
    "xtest_mo = x_train_mocap[3838:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3838 samples, validate on 1098 samples\n",
      "Epoch 1/20\n",
      "3838/3838 [==============================] - 134s - loss: 1.3780 - acc: 0.3619 - val_loss: 1.1874 - val_acc: 0.4818\n",
      "Epoch 2/20\n",
      "3838/3838 [==============================] - 134s - loss: 1.0887 - acc: 0.5328 - val_loss: 1.0259 - val_acc: 0.5765\n",
      "Epoch 3/20\n",
      "3838/3838 [==============================] - 134s - loss: 0.8234 - acc: 0.6701 - val_loss: 0.9108 - val_acc: 0.6248\n",
      "Epoch 4/20\n",
      "3838/3838 [==============================] - 132s - loss: 0.6451 - acc: 0.7603 - val_loss: 1.0393 - val_acc: 0.6211\n",
      "Epoch 5/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.5396 - acc: 0.7934 - val_loss: 0.9689 - val_acc: 0.6384\n",
      "Epoch 6/20\n",
      "3838/3838 [==============================] - 132s - loss: 0.4569 - acc: 0.8236 - val_loss: 0.9315 - val_acc: 0.6840\n",
      "Epoch 7/20\n",
      "3838/3838 [==============================] - 131s - loss: 0.3741 - acc: 0.8551 - val_loss: 1.1224 - val_acc: 0.6321\n",
      "Epoch 8/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.3268 - acc: 0.8768 - val_loss: 1.0418 - val_acc: 0.6639\n",
      "Epoch 9/20\n",
      "3838/3838 [==============================] - 132s - loss: 0.2834 - acc: 0.8882 - val_loss: 1.2462 - val_acc: 0.6475\n",
      "Epoch 10/20\n",
      "3838/3838 [==============================] - 132s - loss: 0.2565 - acc: 0.8973 - val_loss: 1.3563 - val_acc: 0.6585\n",
      "Epoch 11/20\n",
      "3838/3838 [==============================] - 131s - loss: 0.2416 - acc: 0.9049 - val_loss: 1.1327 - val_acc: 0.6685\n",
      "Epoch 12/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.1945 - acc: 0.9252 - val_loss: 1.2870 - val_acc: 0.6749\n",
      "Epoch 13/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.1946 - acc: 0.9203 - val_loss: 1.3988 - val_acc: 0.6730\n",
      "Epoch 14/20\n",
      "3838/3838 [==============================] - 132s - loss: 0.1832 - acc: 0.9270 - val_loss: 1.4882 - val_acc: 0.6776\n",
      "Epoch 15/20\n",
      "3838/3838 [==============================] - 132s - loss: 0.1646 - acc: 0.9338 - val_loss: 1.5878 - val_acc: 0.6375\n",
      "Epoch 16/20\n",
      "3838/3838 [==============================] - 134s - loss: 0.1568 - acc: 0.9377 - val_loss: 1.5469 - val_acc: 0.6703\n",
      "Epoch 17/20\n",
      "3838/3838 [==============================] - 132s - loss: 0.7564 - acc: 0.7129 - val_loss: 0.8586 - val_acc: 0.6785\n",
      "Epoch 18/20\n",
      "3838/3838 [==============================] - 131s - loss: 0.3478 - acc: 0.8627 - val_loss: 0.9505 - val_acc: 0.7104\n",
      "Epoch 19/20\n",
      "3838/3838 [==============================] - 133s - loss: 0.2167 - acc: 0.9171 - val_loss: 1.0780 - val_acc: 0.6922\n",
      "Epoch 20/20\n",
      "3838/3838 [==============================] - 130s - loss: 0.3928 - acc: 0.8471 - val_loss: 1.0349 - val_acc: 0.6685\n"
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([xtrain_tx,xtrain_sp,xtrain_mo], ytrain_sp, \n",
    "                 batch_size=64, nb_epoch=20, verbose=1, \n",
    "                 validation_data=([xtest_tx,xtest_sp,xtest_mo], ytest_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3838 samples, validate on 1098 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3838/3838 [==============================] - 133s - loss: 0.3763 - acc: 0.8525 - val_loss: 0.9981 - val_acc: 0.6658\n",
      "Epoch 2/10\n",
      "3838/3838 [==============================] - 135s - loss: 0.3503 - acc: 0.8606 - val_loss: 1.4561 - val_acc: 0.6184\n",
      "Epoch 3/10\n",
      "3838/3838 [==============================] - 134s - loss: 0.3502 - acc: 0.8637 - val_loss: 1.1833 - val_acc: 0.6667\n",
      "Epoch 4/10\n",
      "3838/3838 [==============================] - 134s - loss: 0.3165 - acc: 0.8760 - val_loss: 1.0661 - val_acc: 0.6740\n",
      "Epoch 5/10\n",
      "3838/3838 [==============================] - 134s - loss: 0.3003 - acc: 0.8796 - val_loss: 1.1590 - val_acc: 0.6694\n",
      "Epoch 6/10\n",
      "3838/3838 [==============================] - 134s - loss: 0.2903 - acc: 0.8867 - val_loss: 1.3824 - val_acc: 0.6175\n",
      "Epoch 7/10\n",
      "3838/3838 [==============================] - 133s - loss: 0.2639 - acc: 0.8960 - val_loss: 1.2120 - val_acc: 0.6694\n",
      "Epoch 8/10\n",
      "3838/3838 [==============================] - 134s - loss: 0.2600 - acc: 0.8999 - val_loss: 1.1252 - val_acc: 0.6821\n",
      "Epoch 9/10\n",
      "3838/3838 [==============================] - 134s - loss: 0.2405 - acc: 0.9044 - val_loss: 1.2397 - val_acc: 0.6639\n",
      "Epoch 10/10\n",
      "3838/3838 [==============================] - 135s - loss: 0.2285 - acc: 0.9114 - val_loss: 1.3532 - val_acc: 0.6457\n"
     ]
    }
   ],
   "source": [
    "hist = model_combined.fit([xtrain_tx,xtrain_sp,xtrain_mo], ytrain_sp, \n",
    "                 batch_size=64, nb_epoch=25, verbose=1, \n",
    "                 validation_data=([xtest_tx,xtest_sp,xtest_mo], ytest_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
